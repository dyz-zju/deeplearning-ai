{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, AveragePooling2D, Activation, GlobalAveragePooling2D, UpSampling2D, Lambda\n",
    "from keras.layers.core import Dropout, Reshape\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import Initializer\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "import pydot\n",
    "import graphviz\n",
    "from keras.utils import plot_model\n",
    "import glob\n",
    "import bcolz\n",
    "import threading\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Open dataset\n",
    "xx_train = bcolz.open('dataset2/x_train.bc')[:]\n",
    "yy_train_encoded = bcolz.open('dataset2/y_train_encoded.bc')[:]\n",
    "\n",
    "xx_train-=0.4\n",
    "xx_train/=0.3\n",
    "\n",
    "x_train = xx_train[:450]\n",
    "y_train = yy_train_encoded[:450]\n",
    "\n",
    "x_validation = xx_train[450:]\n",
    "y_validation = yy_train_encoded[450:]\n",
    "\n",
    "n,r,c,ch = x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchIndices(object):\n",
    "    def __init__(self, n, bs, shuffle=False):\n",
    "        self.n,self.bs,self.shuffle = n,bs,shuffle\n",
    "        self.lock = threading.Lock()\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.idxs = (np.random.permutation(self.n) \n",
    "                     if self.shuffle else np.arange(0, self.n))\n",
    "        self.curr = 0\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            if self.curr >= self.n: self.reset()\n",
    "            ni = min(self.bs, self.n-self.curr)\n",
    "            res = self.idxs[self.curr:self.curr+ni]\n",
    "            self.curr += ni\n",
    "            return res\n",
    "\n",
    "class segm_generator(object):\n",
    "    def __init__(self, x, y, bs=1, out_sz=(256,384), train=True):\n",
    "        self.x, self.y, self.bs, self.train = x,y,bs,train\n",
    "        self.n, self.ri, self.ci, _ = x.shape\n",
    "        self.idx_gen = BatchIndices(self.n, bs, train)\n",
    "        self.ro, self.co = out_sz\n",
    "        self.ych = self.y.shape[-1] if len(y.shape)==4 else 1\n",
    "\n",
    "    def get_slice(self, i,o):\n",
    "        start = random.randint(0, i-o) if self.train else (i-o)\n",
    "        return slice(start, start+o)\n",
    "\n",
    "    def get_item(self, idx):\n",
    "        slice_r = self.get_slice(self.ri, self.ro)\n",
    "        slice_c = self.get_slice(self.ci, self.co)\n",
    "        x = self.x[idx, slice_r, slice_c]\n",
    "        y = self.y[idx, slice_r, slice_c]\n",
    "        if self.train and (random.random()>0.5): \n",
    "            y = y[:,::-1]\n",
    "            x = x[:,::-1]\n",
    "        return x, y\n",
    "\n",
    "    def __next__(self):\n",
    "        idxs = next(self.idx_gen)\n",
    "        items = (self.get_item(idx) for idx in idxs)\n",
    "        xs,ys = zip(*items)\n",
    "        return np.stack(xs), np.stack(ys).reshape(len(ys), -1, self.ych)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = segm_generator(x_train, y_train, 3, train=True)\n",
    "validation_generator = segm_generator(x_validation, y_validation, 3, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Similar to densenet implementation, we define these blocks/layers\n",
    "#The only difference is that now we want to store x_ to be concatenated\n",
    "#into the upsampling part of the network\n",
    "\n",
    "#Since there are downsampling and upsampling part, we also need\n",
    "# to define a new block, transition_layers_upsample\n",
    "\n",
    "def dense_block(x,num_layers_per_block_,growth_rate):\n",
    "    store_x_ = []\n",
    "    for i in range(num_layers_per_block_):\n",
    "        x_ = BatchNormalization()(x)\n",
    "        x_ = Activation('relu')(x_)\n",
    "        x_ = Conv2D(growth_rate,(3,3),padding='same',\n",
    "                    kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=l2(0.0001))(x_)\n",
    "        x_ = Dropout(0.2)(x_)\n",
    "        store_x_.append(x_)\n",
    "        x = Concatenate()([x,x_])\n",
    "    return x, store_x_\n",
    "\n",
    "def transition_downsample_layers(x):\n",
    "    updated_num_filters = int(x.get_shape().as_list()[-1])\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(updated_num_filters,(1,1),padding='same',\n",
    "               kernel_initializer='he_normal',\n",
    "               kernel_regularizer=l2(0.0001))(x)\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    return x\n",
    "\n",
    "def transition_upsample_layers(store_x_):\n",
    "    x = Concatenate()(store_x_)\n",
    "    x = UpSampling2D()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define model parameters\n",
    "num_dense_blocks = 6\n",
    "growth_rate = 16\n",
    "number_filters = 48\n",
    "num_layers_per_block = [4,5,7,10,12,15] #see in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Let's define the model\n",
    "inp = Input((256, 384, 3))\n",
    "x = Conv2D(number_filters,(3,3),padding='same',\n",
    "           kernel_initializer='he_normal',\n",
    "           kernel_regularizer=l2(0.0001))(inp)\n",
    "\n",
    "#Downsample\n",
    "skip_connection = []\n",
    "for i in range(len(num_layers_per_block)):\n",
    "    x,store_x_ = dense_block(x,num_layers_per_block[i],growth_rate)\n",
    "    skip_connection.append(x)\n",
    "    x = transition_downsample_layers(x)\n",
    "    \n",
    "#Upsample\n",
    "skip_connection_ = (skip_connection[:-1])[::-1]\n",
    "num_layers_per_block_ = (num_layers_per_block[:-1])[::-1]\n",
    "for i in range(len(num_layers_per_block_)):\n",
    "    x = transition_upsample_layers(store_x_)\n",
    "    x = Concatenate()([x,skip_connection_[i]])\n",
    "    x,store_x_ = dense_block(x,num_layers_per_block_[i],growth_rate)\n",
    "\n",
    "x = Conv2D(32,(1,1),padding='same',\n",
    "           kernel_initializer='he_normal',\n",
    "           kernel_regularizer=l2(0.0001))(x)\n",
    "x = Reshape((-1, 32))(x)\n",
    "x = Activation('softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inp, x)\n",
    "model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "plot_model(model, to_file='model_256by384_augmented.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "400s - loss: 0.8348 - acc: 0.8043 - val_loss: 0.8275 - val_acc: 0.8037\n",
      "Epoch 2/70\n",
      "400s - loss: 0.7696 - acc: 0.8222 - val_loss: 0.7403 - val_acc: 0.8292\n",
      "Epoch 3/70\n",
      "400s - loss: 0.7165 - acc: 0.8341 - val_loss: 0.6596 - val_acc: 0.8466\n",
      "Epoch 4/70\n",
      "399s - loss: 0.6746 - acc: 0.8425 - val_loss: 0.7358 - val_acc: 0.8388\n",
      "Epoch 5/70\n",
      "400s - loss: 0.6524 - acc: 0.8479 - val_loss: 0.7393 - val_acc: 0.8191\n",
      "Epoch 6/70\n",
      "400s - loss: 0.6183 - acc: 0.8570 - val_loss: 0.6798 - val_acc: 0.8480\n",
      "Epoch 7/70\n",
      "400s - loss: 0.5986 - acc: 0.8602 - val_loss: 0.5946 - val_acc: 0.8614\n",
      "Epoch 8/70\n",
      "400s - loss: 0.5893 - acc: 0.8626 - val_loss: 0.6806 - val_acc: 0.8545\n",
      "Epoch 9/70\n",
      "400s - loss: 0.5730 - acc: 0.8674 - val_loss: 0.8109 - val_acc: 0.8183\n",
      "Epoch 10/70\n",
      "400s - loss: 0.5582 - acc: 0.8707 - val_loss: 0.5416 - val_acc: 0.8764\n",
      "Epoch 11/70\n",
      "400s - loss: 0.5467 - acc: 0.8725 - val_loss: 0.6212 - val_acc: 0.8635\n",
      "Epoch 12/70\n",
      "400s - loss: 0.5345 - acc: 0.8756 - val_loss: 0.7018 - val_acc: 0.8357\n",
      "Epoch 13/70\n",
      "400s - loss: 0.5315 - acc: 0.8759 - val_loss: 0.6033 - val_acc: 0.8631\n",
      "Epoch 14/70\n",
      "400s - loss: 0.5215 - acc: 0.8785 - val_loss: 0.6073 - val_acc: 0.8627\n",
      "Epoch 15/70\n",
      "400s - loss: 0.5048 - acc: 0.8819 - val_loss: 0.5231 - val_acc: 0.8809\n",
      "Epoch 16/70\n",
      "400s - loss: 0.4984 - acc: 0.8834 - val_loss: 0.5938 - val_acc: 0.8662\n",
      "Epoch 17/70\n",
      "400s - loss: 0.4915 - acc: 0.8856 - val_loss: 0.5867 - val_acc: 0.8726\n",
      "Epoch 18/70\n",
      "400s - loss: 0.4907 - acc: 0.8852 - val_loss: 0.6114 - val_acc: 0.8599\n",
      "Epoch 19/70\n",
      "400s - loss: 0.4845 - acc: 0.8870 - val_loss: 0.5334 - val_acc: 0.8811\n",
      "Epoch 20/70\n",
      "400s - loss: 0.4756 - acc: 0.8889 - val_loss: 0.6424 - val_acc: 0.8561\n",
      "Epoch 21/70\n",
      "400s - loss: 0.4666 - acc: 0.8909 - val_loss: 0.5368 - val_acc: 0.8797\n",
      "Epoch 22/70\n",
      "400s - loss: 0.4606 - acc: 0.8922 - val_loss: 0.5647 - val_acc: 0.8709\n",
      "Epoch 23/70\n",
      "400s - loss: 0.4596 - acc: 0.8926 - val_loss: 0.5859 - val_acc: 0.8676\n",
      "Epoch 24/70\n",
      "400s - loss: 0.4521 - acc: 0.8938 - val_loss: 0.5175 - val_acc: 0.8814\n",
      "Epoch 25/70\n",
      "400s - loss: 0.4518 - acc: 0.8945 - val_loss: 0.4889 - val_acc: 0.8879\n",
      "Epoch 26/70\n",
      "400s - loss: 0.4483 - acc: 0.8952 - val_loss: 0.4566 - val_acc: 0.8967\n",
      "Epoch 27/70\n",
      "400s - loss: 0.4411 - acc: 0.8971 - val_loss: 0.4936 - val_acc: 0.8893\n",
      "Epoch 28/70\n",
      "400s - loss: 0.4385 - acc: 0.8974 - val_loss: 0.6606 - val_acc: 0.8536\n",
      "Epoch 29/70\n",
      "400s - loss: 0.4367 - acc: 0.8981 - val_loss: 0.5855 - val_acc: 0.8799\n",
      "Epoch 30/70\n",
      "400s - loss: 0.4329 - acc: 0.8985 - val_loss: 0.5955 - val_acc: 0.8674\n",
      "Epoch 31/70\n",
      "400s - loss: 0.4262 - acc: 0.9000 - val_loss: 0.4775 - val_acc: 0.8916\n",
      "Epoch 32/70\n",
      "400s - loss: 0.4245 - acc: 0.9003 - val_loss: 0.5601 - val_acc: 0.8665\n",
      "Epoch 33/70\n",
      "400s - loss: 0.4242 - acc: 0.9003 - val_loss: 0.4966 - val_acc: 0.8899\n",
      "Epoch 34/70\n",
      "400s - loss: 0.4173 - acc: 0.9022 - val_loss: 0.4975 - val_acc: 0.8874\n",
      "Epoch 35/70\n",
      "400s - loss: 0.4242 - acc: 0.9003 - val_loss: 0.5003 - val_acc: 0.8918\n",
      "Epoch 36/70\n",
      "400s - loss: 0.4148 - acc: 0.9027 - val_loss: 0.4621 - val_acc: 0.8954\n",
      "Epoch 37/70\n",
      "400s - loss: 0.4104 - acc: 0.9038 - val_loss: 0.5044 - val_acc: 0.8856\n",
      "Epoch 38/70\n",
      "400s - loss: 0.4143 - acc: 0.9030 - val_loss: 0.5256 - val_acc: 0.8888\n",
      "Epoch 39/70\n",
      "400s - loss: 0.4090 - acc: 0.9038 - val_loss: 0.7343 - val_acc: 0.8300\n",
      "Epoch 40/70\n",
      "400s - loss: 0.4077 - acc: 0.9043 - val_loss: 0.4893 - val_acc: 0.8888\n",
      "Epoch 41/70\n",
      "400s - loss: 0.4010 - acc: 0.9058 - val_loss: 0.5048 - val_acc: 0.8839\n",
      "Epoch 42/70\n",
      "400s - loss: 0.4047 - acc: 0.9043 - val_loss: 1.0477 - val_acc: 0.8282\n",
      "Epoch 43/70\n",
      "400s - loss: 0.4016 - acc: 0.9057 - val_loss: 0.7624 - val_acc: 0.8354\n",
      "Epoch 44/70\n",
      "400s - loss: 0.4000 - acc: 0.9058 - val_loss: 0.5852 - val_acc: 0.8658\n",
      "Epoch 45/70\n",
      "400s - loss: 0.3998 - acc: 0.9060 - val_loss: 0.4786 - val_acc: 0.8910\n",
      "Epoch 46/70\n",
      "400s - loss: 0.3916 - acc: 0.9076 - val_loss: 0.4651 - val_acc: 0.8996\n",
      "Epoch 47/70\n",
      "400s - loss: 0.3968 - acc: 0.9064 - val_loss: 0.5084 - val_acc: 0.8883\n",
      "Epoch 48/70\n",
      "400s - loss: 0.3901 - acc: 0.9080 - val_loss: 0.4500 - val_acc: 0.9005\n",
      "Epoch 49/70\n",
      "400s - loss: 0.3939 - acc: 0.9070 - val_loss: 0.4523 - val_acc: 0.9011\n",
      "Epoch 50/70\n",
      "400s - loss: 0.3908 - acc: 0.9078 - val_loss: 0.4718 - val_acc: 0.8954\n",
      "Epoch 51/70\n",
      "400s - loss: 0.3884 - acc: 0.9083 - val_loss: 0.4552 - val_acc: 0.8952\n",
      "Epoch 52/70\n",
      "400s - loss: 0.3908 - acc: 0.9082 - val_loss: 0.4440 - val_acc: 0.8988\n",
      "Epoch 53/70\n",
      "400s - loss: 0.3841 - acc: 0.9093 - val_loss: 0.4704 - val_acc: 0.8976\n",
      "Epoch 54/70\n",
      "400s - loss: 0.3884 - acc: 0.9085 - val_loss: 0.5109 - val_acc: 0.8795\n",
      "Epoch 55/70\n",
      "400s - loss: 0.3840 - acc: 0.9094 - val_loss: 0.4549 - val_acc: 0.8999\n",
      "Epoch 56/70\n",
      "400s - loss: 0.3811 - acc: 0.9098 - val_loss: 0.4563 - val_acc: 0.8973\n",
      "Epoch 57/70\n",
      "400s - loss: 0.3794 - acc: 0.9103 - val_loss: 0.4593 - val_acc: 0.9022\n",
      "Epoch 58/70\n",
      "400s - loss: 0.3803 - acc: 0.9101 - val_loss: 0.5274 - val_acc: 0.8863\n",
      "Epoch 59/70\n",
      "400s - loss: 0.3818 - acc: 0.9091 - val_loss: 0.5106 - val_acc: 0.8912\n",
      "Epoch 60/70\n",
      "400s - loss: 0.3790 - acc: 0.9102 - val_loss: 0.4437 - val_acc: 0.9017\n",
      "Epoch 61/70\n",
      "400s - loss: 0.3779 - acc: 0.9102 - val_loss: 0.4525 - val_acc: 0.9008\n",
      "Epoch 62/70\n",
      "400s - loss: 0.3804 - acc: 0.9098 - val_loss: 0.4255 - val_acc: 0.9017\n",
      "Epoch 63/70\n",
      "400s - loss: 0.3759 - acc: 0.9113 - val_loss: 0.4269 - val_acc: 0.9056\n",
      "Epoch 64/70\n",
      "400s - loss: 0.3721 - acc: 0.9116 - val_loss: 0.5230 - val_acc: 0.8871\n",
      "Epoch 65/70\n",
      "400s - loss: 0.3798 - acc: 0.9098 - val_loss: 0.6484 - val_acc: 0.8731\n",
      "Epoch 66/70\n",
      "400s - loss: 0.3739 - acc: 0.9117 - val_loss: 0.4726 - val_acc: 0.8947\n",
      "Epoch 67/70\n",
      "400s - loss: 0.3732 - acc: 0.9118 - val_loss: 0.4786 - val_acc: 0.8902\n",
      "Epoch 68/70\n",
      "400s - loss: 0.3708 - acc: 0.9122 - val_loss: 0.4318 - val_acc: 0.9032\n",
      "Epoch 69/70\n",
      "400s - loss: 0.3720 - acc: 0.9117 - val_loss: 0.5255 - val_acc: 0.8898\n",
      "Epoch 70/70\n",
      "400s - loss: 0.3688 - acc: 0.9126 - val_loss: 0.5026 - val_acc: 0.8887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb2fe6d1860>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train_generator, len(x_train), epochs=70, \n",
    "                    validation_data=validation_generator, \n",
    "                    validation_steps=len(x_validation),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('tiramisu256by384_augmented_70epochs_model_weights.h5')\n",
    "model.save_weights('tiramisu256by384_augmented_70epochs_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_code(l):\n",
    "    a = l.strip().split(\"\\t\")\n",
    "    codes = tuple(int(o) for o in a[0].split(' '))\n",
    "    names = a[1]\n",
    "    return codes,names\n",
    "\n",
    "def color_label(a): \n",
    "    r,c=a.shape\n",
    "    res = np.zeros((r,c,3), 'uint8')\n",
    "    for j in range(r): \n",
    "        for k in range(c):\n",
    "            var = id2code[a[j,k]]\n",
    "            res[j,k] = var\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_codes,label_names = zip(*[parse_code(l) for l in open(\"dataset_unsplitted/label_colors.txt\")])\n",
    "code2id = {v:k for k,v in enumerate(label_codes)}\n",
    "id2code = {k:v for k,v in enumerate(label_codes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(validation_generator,\n",
    "                                      len(x_validation))\n",
    "predictions = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(color_label(np.resize(predictions[0], (224,224))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = x_validation[4,:224,96:]\n",
    "im = np.expand_dims(t,axis=0)\n",
    "p = model.predict(im)\n",
    "p_arg = np.argmax(p, axis=-1)\n",
    "p_arg_resized = np.resize(p[0], (224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx= 10\n",
    "t = np.resize(x_validation[idx],(256,384,3))\n",
    "im = np.expand_dims(t,axis=0)\n",
    "p = model.predict(im)\n",
    "p_arg = np.argmax(p, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb2fc717c50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD8CAYAAABq6S8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n5CIiiVOQi4gkTkEuIpI4BbmISOL+PwGMbgl1MCsSAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb2fc7a1a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(color_label(np.resize(p_arg[0], (256,384))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
