{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D,\\\n",
    "        UpSampling2D, Lambda, Activation, merge\n",
    "from keras.layers.core import Dropout, Reshape, Flatten\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.initializers import Initializer\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import plot_model\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "import pydot\n",
    "import graphviz\n",
    "from PIL import Image\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imsave\n",
    "import bcolz\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''LOAD MNIST'''\n",
    "(x_all, y_all), (x_test, y_test) = mnist.load_data()\n",
    "x_all = x_all/255.0\n",
    "x_test = x_test/255.0\n",
    "\n",
    "x_train = x_all[:50000]\n",
    "y_train = y_all[:50000]\n",
    "x_validate = x_all[50000:]\n",
    "y_validate = y_all[50000:]\n",
    "\n",
    "x_train = np.expand_dims(x_train, axis=3)\n",
    "x_validate = np.expand_dims(x_validate, axis=3)\n",
    "x_test = np.expand_dims(x_test, axis=3)\n",
    "\n",
    "num_classes = 10\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_validate = to_categorical(y_validate, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "input_shape = x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define and Train Classifier, Freeze Classifier After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_inp = Input(x_train.shape[1:])\n",
    "conv1 = Conv2D(32, (3, 3),\n",
    "                      activation = 'relu',\n",
    "                      padding = 'same')(classifier_inp)\n",
    "conv2 = Conv2D(64, (3, 3),\n",
    "                      activation = 'relu',\n",
    "                      padding = 'same')(conv1)\n",
    "classifier = MaxPooling2D()(conv2)\n",
    "classifier = Dropout(0.25)(classifier)\n",
    "classifier = Flatten()(classifier)\n",
    "classifier = Dense(128, activation = 'relu')(classifier)\n",
    "classifier = Dropout(0.5)(classifier)\n",
    "classifier = Dense(num_classes, activation = 'softmax')(classifier)\n",
    "classifier = Model(classifier_inp,classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier.compile(Adam(),\n",
    "                   loss = 'categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 3s - loss: 0.4553 - acc: 0.8581 - val_loss: 0.1088 - val_acc: 0.9683\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.1332 - acc: 0.9617 - val_loss: 0.0667 - val_acc: 0.9800\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0916 - acc: 0.9722 - val_loss: 0.0573 - val_acc: 0.9831\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0710 - acc: 0.9781 - val_loss: 0.0497 - val_acc: 0.9863\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0621 - acc: 0.9811 - val_loss: 0.0445 - val_acc: 0.9868\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0521 - acc: 0.9841 - val_loss: 0.0447 - val_acc: 0.9879\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0500 - acc: 0.9847 - val_loss: 0.0382 - val_acc: 0.9898\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0410 - acc: 0.9873 - val_loss: 0.0394 - val_acc: 0.9893\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0384 - acc: 0.9876 - val_loss: 0.0380 - val_acc: 0.9899\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0350 - acc: 0.9887 - val_loss: 0.0371 - val_acc: 0.9896\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0318 - acc: 0.9897 - val_loss: 0.0387 - val_acc: 0.9900\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0296 - acc: 0.9906 - val_loss: 0.0350 - val_acc: 0.9898\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0272 - acc: 0.9911 - val_loss: 0.0381 - val_acc: 0.9897\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0263 - acc: 0.9914 - val_loss: 0.0401 - val_acc: 0.9902\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0223 - acc: 0.9923 - val_loss: 0.0388 - val_acc: 0.9904\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - ETA: 0s - loss: 0.0229 - acc: 0.992 - 2s - loss: 0.0230 - acc: 0.9926 - val_loss: 0.0376 - val_acc: 0.9912\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0214 - acc: 0.9925 - val_loss: 0.0381 - val_acc: 0.9897\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0200 - acc: 0.9933 - val_loss: 0.0391 - val_acc: 0.9914\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0191 - acc: 0.9935 - val_loss: 0.0383 - val_acc: 0.9911\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0173 - acc: 0.9944 - val_loss: 0.0426 - val_acc: 0.9904\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0171 - acc: 0.9941 - val_loss: 0.0414 - val_acc: 0.9912\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0173 - acc: 0.9941 - val_loss: 0.0379 - val_acc: 0.9904\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0167 - acc: 0.9946 - val_loss: 0.0394 - val_acc: 0.9911\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0148 - acc: 0.9949 - val_loss: 0.0425 - val_acc: 0.9900\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0143 - acc: 0.9951 - val_loss: 0.0424 - val_acc: 0.9909\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0159 - acc: 0.9948 - val_loss: 0.0407 - val_acc: 0.9911\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0143 - acc: 0.9951 - val_loss: 0.0387 - val_acc: 0.9914\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0140 - acc: 0.9952 - val_loss: 0.0418 - val_acc: 0.9913\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0122 - acc: 0.9958 - val_loss: 0.0431 - val_acc: 0.9911\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0124 - acc: 0.9956 - val_loss: 0.0412 - val_acc: 0.9911\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0123 - acc: 0.9958 - val_loss: 0.0426 - val_acc: 0.9908\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0109 - acc: 0.9960 - val_loss: 0.0435 - val_acc: 0.9909\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0143 - acc: 0.9953 - val_loss: 0.0399 - val_acc: 0.9912\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0107 - acc: 0.9967 - val_loss: 0.0436 - val_acc: 0.9911\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0111 - acc: 0.9961 - val_loss: 0.0408 - val_acc: 0.9916\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0098 - acc: 0.9967 - val_loss: 0.0418 - val_acc: 0.9912\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0113 - acc: 0.9960 - val_loss: 0.0418 - val_acc: 0.9910\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0101 - acc: 0.9965 - val_loss: 0.0425 - val_acc: 0.9923\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0112 - acc: 0.9957 - val_loss: 0.0409 - val_acc: 0.9911\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0103 - acc: 0.9966 - val_loss: 0.0423 - val_acc: 0.9919\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0095 - acc: 0.9969 - val_loss: 0.0451 - val_acc: 0.9902\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0096 - acc: 0.9967 - val_loss: 0.0467 - val_acc: 0.9920\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0083 - acc: 0.9974 - val_loss: 0.0453 - val_acc: 0.9922\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0092 - acc: 0.9967 - val_loss: 0.0453 - val_acc: 0.9909\n",
      "Epoch 45/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0100 - acc: 0.9965 - val_loss: 0.0444 - val_acc: 0.9918\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0080 - acc: 0.9972 - val_loss: 0.0441 - val_acc: 0.9913\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0098 - acc: 0.9966 - val_loss: 0.0426 - val_acc: 0.9920\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0094 - acc: 0.9966 - val_loss: 0.0413 - val_acc: 0.9922\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0078 - acc: 0.9973 - val_loss: 0.0414 - val_acc: 0.9922\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0075 - acc: 0.9973 - val_loss: 0.0467 - val_acc: 0.9916\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0087 - acc: 0.9970 - val_loss: 0.0437 - val_acc: 0.9920\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0082 - acc: 0.9972 - val_loss: 0.0482 - val_acc: 0.9907\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0084 - acc: 0.9971 - val_loss: 0.0433 - val_acc: 0.9924\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0072 - acc: 0.9974 - val_loss: 0.0443 - val_acc: 0.9908\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0074 - acc: 0.9977 - val_loss: 0.0453 - val_acc: 0.9913\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0067 - acc: 0.9975 - val_loss: 0.0474 - val_acc: 0.9920\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0067 - acc: 0.9976 - val_loss: 0.0489 - val_acc: 0.9915\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0073 - acc: 0.9976 - val_loss: 0.0499 - val_acc: 0.9907\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0085 - acc: 0.9971 - val_loss: 0.0457 - val_acc: 0.9920\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0071 - acc: 0.9976 - val_loss: 0.0458 - val_acc: 0.9922\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0066 - acc: 0.9977 - val_loss: 0.0478 - val_acc: 0.9917\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0070 - acc: 0.9973 - val_loss: 0.0483 - val_acc: 0.9918\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0063 - acc: 0.9980 - val_loss: 0.0452 - val_acc: 0.9911\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0058 - acc: 0.9979 - val_loss: 0.0482 - val_acc: 0.9921\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0065 - acc: 0.9977 - val_loss: 0.0444 - val_acc: 0.9919\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0056 - acc: 0.9981 - val_loss: 0.0481 - val_acc: 0.9926\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0067 - acc: 0.9976 - val_loss: 0.0440 - val_acc: 0.9924\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0054 - acc: 0.9980 - val_loss: 0.0513 - val_acc: 0.9915\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0067 - acc: 0.9976 - val_loss: 0.0493 - val_acc: 0.9914\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0062 - acc: 0.9979 - val_loss: 0.0481 - val_acc: 0.9918\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0063 - acc: 0.9979 - val_loss: 0.0462 - val_acc: 0.9924\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0064 - acc: 0.9977 - val_loss: 0.0510 - val_acc: 0.9921\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0064 - acc: 0.9977 - val_loss: 0.0469 - val_acc: 0.9925\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0053 - acc: 0.9979 - val_loss: 0.0476 - val_acc: 0.9924\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0053 - acc: 0.9981 - val_loss: 0.0515 - val_acc: 0.9921\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0506 - val_acc: 0.9918\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0478 - val_acc: 0.9923\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0061 - acc: 0.9977 - val_loss: 0.0506 - val_acc: 0.9916\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0063 - acc: 0.9978 - val_loss: 0.0455 - val_acc: 0.9929\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0046 - acc: 0.9983 - val_loss: 0.0433 - val_acc: 0.9919\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0496 - val_acc: 0.9914\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0051 - acc: 0.9983 - val_loss: 0.0459 - val_acc: 0.9920\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0062 - acc: 0.9980 - val_loss: 0.0451 - val_acc: 0.9927\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0052 - acc: 0.9984 - val_loss: 0.0490 - val_acc: 0.9923\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0441 - val_acc: 0.9929\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0474 - val_acc: 0.9915\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0059 - acc: 0.9980 - val_loss: 0.0442 - val_acc: 0.9922\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0056 - acc: 0.9979 - val_loss: 0.0470 - val_acc: 0.9924\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0052 - acc: 0.9980 - val_loss: 0.0433 - val_acc: 0.9930\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0042 - acc: 0.9985 - val_loss: 0.0484 - val_acc: 0.9913\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0047 - acc: 0.9983 - val_loss: 0.0495 - val_acc: 0.9918\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0034 - acc: 0.9989 - val_loss: 0.0530 - val_acc: 0.9923\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0042 - acc: 0.9985 - val_loss: 0.0496 - val_acc: 0.9919\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0043 - acc: 0.9985 - val_loss: 0.0520 - val_acc: 0.9925\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0045 - acc: 0.9982 - val_loss: 0.0514 - val_acc: 0.9926\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0039 - acc: 0.9986 - val_loss: 0.0493 - val_acc: 0.9925\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0044 - acc: 0.9986 - val_loss: 0.0460 - val_acc: 0.9921\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0045 - acc: 0.9983 - val_loss: 0.0481 - val_acc: 0.9928\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0047 - acc: 0.9982 - val_loss: 0.0498 - val_acc: 0.9922\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 2s - loss: 0.0052 - acc: 0.9982 - val_loss: 0.0447 - val_acc: 0.9927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f23ce069e80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(x_train, y_train,\n",
    "          batch_size = 512,\n",
    "          epochs = 100,\n",
    "          verbose = 1,\n",
    "          validation_data = (x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy: 99.39%\n"
     ]
    }
   ],
   "source": [
    "classifier_accuracy = classifier.evaluate(x_test, y_test, verbose=0)\n",
    "print('Classifier accuracy: %.2f%%' % (classifier_accuracy[1] * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Make our classifier not trainable'''\n",
    "classifier.trainable = False\n",
    "for layer in classifier.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Generative Model and Train It"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Prepare perception target - Functional'''\n",
    "percept = Model(classifier_inp,conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 28, 28, 64), (10000, 28, 28, 64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percept_train = percept.predict(x_train)\n",
    "percept_validate = percept.predict(x_validate)\n",
    "\n",
    "percept_train.shape, percept_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''Prepare adversarial target'''\n",
    "y0_train = np.zeros((x_train.shape[0],10))\n",
    "y0_train[:,0] = 1.0\n",
    "y0_validate = np.zeros((x_validate.shape[0],10))\n",
    "y0_validate[:,0] = 1.0\n",
    "\n",
    "y1_train = np.zeros((x_train.shape[0],10))\n",
    "y1_train[:,1] = 1.0\n",
    "y1_validate = np.zeros((x_validate.shape[0],10))\n",
    "y1_validate[:,1] = 1.0\n",
    "\n",
    "y2_train = np.zeros((x_train.shape[0],10))\n",
    "y2_train[:,2] = 1.0\n",
    "y2_validate = np.zeros((x_validate.shape[0],10))\n",
    "y2_validate[:,2] = 1.0\n",
    "\n",
    "y3_train = np.zeros((x_train.shape[0],10))\n",
    "y3_train[:,3] = 1.0\n",
    "y3_validate = np.zeros((x_validate.shape[0],10))\n",
    "y3_validate[:,3] = 1.0\n",
    "\n",
    "y4_train = np.zeros((x_train.shape[0],10))\n",
    "y4_train[:,4] = 1.0\n",
    "y4_validate = np.zeros((x_validate.shape[0],10))\n",
    "y4_validate[:,4] = 1.0\n",
    "\n",
    "y5_train = np.zeros((x_train.shape[0],10))\n",
    "y5_train[:,5] = 1.0\n",
    "y5_validate = np.zeros((x_validate.shape[0],10))\n",
    "y5_validate[:,5] = 1.0\n",
    "\n",
    "y6_train = np.zeros((x_train.shape[0],10))\n",
    "y6_train[:,6] = 1.0\n",
    "y6_validate = np.zeros((x_validate.shape[0],10))\n",
    "y6_validate[:,6] = 1.0\n",
    "\n",
    "y7_train = np.zeros((x_train.shape[0],10))\n",
    "y7_train[:,7] = 1.0\n",
    "y7_validate = np.zeros((x_validate.shape[0],10))\n",
    "y7_validate[:,7] = 1.0\n",
    "\n",
    "y8_train = np.zeros((x_train.shape[0],10))\n",
    "y8_train[:,8] = 1.0\n",
    "y8_validate = np.zeros((x_validate.shape[0],10))\n",
    "y8_validate[:,8] = 1.0\n",
    "\n",
    "y9_train = np.zeros((x_train.shape[0],10))\n",
    "y9_train[:,9] = 1.0\n",
    "y9_validate = np.zeros((x_validate.shape[0],10))\n",
    "y9_validate[:,9] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, (size,size), strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation == True:\n",
    "        x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def residual_block(blockInput, num_filters=64):\n",
    "    x = convolution_block(blockInput, num_filters, 3)\n",
    "    x = convolution_block(x, num_filters, 3, activation=False)\n",
    "    x = merge([x, blockInput], mode='sum')\n",
    "    return x\n",
    "\n",
    "def upsampling_block(x, filters, size):\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(filters, (size,size), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:11: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.5/dist-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n"
     ]
    }
   ],
   "source": [
    "classifier.trainable = False\n",
    "for layer in classifier.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "percept.trainable = False\n",
    "for layer in percept.layers:\n",
    "    percept.trainable = False\n",
    "\n",
    "'''NETWORK #0'''\n",
    "inp0 = Input(x_train.shape[1:])\n",
    "x0 = convolution_block(inp0, 64, 9)\n",
    "x0 = residual_block(x0)\n",
    "x0 = residual_block(x0)\n",
    "x0 = residual_block(x0)\n",
    "x0 = residual_block(x0)\n",
    "out0 = Conv2D(1, (9,9), activation = 'sigmoid', padding='same')(x0)\n",
    "percept0 = percept(out0)\n",
    "y0 = classifier(out0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model0 = Model(inp0, [percept0, y0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 28, 28, 1)     0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                (None, 28, 28, 64)    5248        input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNorm (None, 28, 28, 64)    256         conv2d_3[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 28, 28, 64)    0           batch_normalization_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                (None, 28, 28, 64)    36928       activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNorm (None, 28, 28, 64)    256         conv2d_4[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 28, 28, 64)    0           batch_normalization_2[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                (None, 28, 28, 64)    36928       activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNorm (None, 28, 28, 64)    256         conv2d_5[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 28, 28, 64)    0           batch_normalization_3[0][0]      \n",
      "                                                                   activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                (None, 28, 28, 64)    36928       merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNorm (None, 28, 28, 64)    256         conv2d_6[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 28, 28, 64)    0           batch_normalization_4[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                (None, 28, 28, 64)    36928       activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNorm (None, 28, 28, 64)    256         conv2d_7[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 28, 28, 64)    0           batch_normalization_5[0][0]      \n",
      "                                                                   merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                (None, 28, 28, 64)    36928       merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNorm (None, 28, 28, 64)    256         conv2d_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 28, 28, 64)    0           batch_normalization_6[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                (None, 28, 28, 64)    36928       activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNorm (None, 28, 28, 64)    256         conv2d_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "merge_3 (Merge)                  (None, 28, 28, 64)    0           batch_normalization_7[0][0]      \n",
      "                                                                   merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)               (None, 28, 28, 64)    36928       merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNorm (None, 28, 28, 64)    256         conv2d_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 28, 28, 64)    0           batch_normalization_8[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)               (None, 28, 28, 64)    36928       activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNorm (None, 28, 28, 64)    256         conv2d_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "merge_4 (Merge)                  (None, 28, 28, 64)    0           batch_normalization_9[0][0]      \n",
      "                                                                   merge_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)               (None, 28, 28, 1)     5185        merge_4[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 28, 28, 64)    18816       conv2d_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 10)            1625866     conv2d_12[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,934,027\n",
      "Trainable params: 307,009\n",
      "Non-trainable params: 1,627,018\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(model0, to_file='model0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model0.compile(Adam(), \n",
    "            loss = {'model_2': 'mean_squared_error', 'model_1': 'categorical_crossentropy'},\n",
    "            loss_weights = {'model_2': 250.0, 'model_1': 1.0}) #model_2 = perception, model_1 = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "50000/50000 [==============================] - 38s - loss: 11.5771 - model_2_loss: 0.0251 - model_1_loss: 5.3049 - val_loss: 11.4807 - val_model_2_loss: 0.0139 - val_model_1_loss: 7.9984\n",
      "Epoch 2/1000\n",
      "50000/50000 [==============================] - 37s - loss: 5.5380 - model_2_loss: 0.0199 - model_1_loss: 0.5526 - val_loss: 6.1284 - val_model_2_loss: 0.0136 - val_model_1_loss: 2.7343\n",
      "Epoch 3/1000\n",
      "50000/50000 [==============================] - 37s - loss: 4.4762 - model_2_loss: 0.0167 - model_1_loss: 0.2958 - val_loss: 5.0814 - val_model_2_loss: 0.0133 - val_model_1_loss: 1.7667\n",
      "Epoch 4/1000\n",
      "50000/50000 [==============================] - 38s - loss: 3.9075 - model_2_loss: 0.0147 - model_1_loss: 0.2333 - val_loss: 4.4987 - val_model_2_loss: 0.0130 - val_model_1_loss: 1.2460\n",
      "Epoch 5/1000\n",
      "50000/50000 [==============================] - 37s - loss: 3.5464 - model_2_loss: 0.0134 - model_1_loss: 0.2059 - val_loss: 3.4011 - val_model_2_loss: 0.0125 - val_model_1_loss: 0.2691\n",
      "Epoch 6/1000\n",
      "50000/50000 [==============================] - 38s - loss: 3.2931 - model_2_loss: 0.0124 - model_1_loss: 0.1863 - val_loss: 3.0557 - val_model_2_loss: 0.0120 - val_model_1_loss: 0.0666\n",
      "Epoch 7/1000\n",
      "50000/50000 [==============================] - 38s - loss: 3.0938 - model_2_loss: 0.0117 - model_1_loss: 0.1769 - val_loss: 2.8979 - val_model_2_loss: 0.0114 - val_model_1_loss: 0.0407\n",
      "Epoch 8/1000\n",
      "50000/50000 [==============================] - 38s - loss: 2.9285 - model_2_loss: 0.0110 - model_1_loss: 0.1779 - val_loss: 2.7911 - val_model_2_loss: 0.0110 - val_model_1_loss: 0.0339\n",
      "Epoch 9/1000\n",
      "50000/50000 [==============================] - 38s - loss: 2.7739 - model_2_loss: 0.0104 - model_1_loss: 0.1719 - val_loss: 2.6650 - val_model_2_loss: 0.0105 - val_model_1_loss: 0.0330\n",
      "Epoch 10/1000\n",
      "50000/50000 [==============================] - 38s - loss: 2.6308 - model_2_loss: 0.0098 - model_1_loss: 0.1747 - val_loss: 2.4833 - val_model_2_loss: 0.0097 - val_model_1_loss: 0.0535\n",
      "Epoch 11/1000\n",
      "50000/50000 [==============================] - 38s - loss: 2.4966 - model_2_loss: 0.0093 - model_1_loss: 0.1783 - val_loss: 2.3307 - val_model_2_loss: 0.0091 - val_model_1_loss: 0.0576\n",
      "Epoch 12/1000\n",
      "50000/50000 [==============================] - 38s - loss: 2.3409 - model_2_loss: 0.0087 - model_1_loss: 0.1699 - val_loss: 2.1805 - val_model_2_loss: 0.0084 - val_model_1_loss: 0.0738\n",
      "Epoch 13/1000\n",
      "50000/50000 [==============================] - 38s - loss: 2.2213 - model_2_loss: 0.0082 - model_1_loss: 0.1681 - val_loss: 2.0714 - val_model_2_loss: 0.0080 - val_model_1_loss: 0.0653\n",
      "Epoch 14/1000\n",
      "50000/50000 [==============================] - 38s - loss: 2.1203 - model_2_loss: 0.0078 - model_1_loss: 0.1583 - val_loss: 1.9673 - val_model_2_loss: 0.0076 - val_model_1_loss: 0.0683\n",
      "Epoch 15/1000\n",
      "50000/50000 [==============================] - 38s - loss: 2.0417 - model_2_loss: 0.0075 - model_1_loss: 0.1554 - val_loss: 1.9023 - val_model_2_loss: 0.0074 - val_model_1_loss: 0.0570\n",
      "Epoch 16/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.9815 - model_2_loss: 0.0073 - model_1_loss: 0.1514 - val_loss: 1.8712 - val_model_2_loss: 0.0073 - val_model_1_loss: 0.0357\n",
      "Epoch 17/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.9193 - model_2_loss: 0.0071 - model_1_loss: 0.1448 - val_loss: 1.7839 - val_model_2_loss: 0.0069 - val_model_1_loss: 0.0566\n",
      "Epoch 18/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.8737 - model_2_loss: 0.0069 - model_1_loss: 0.1414 - val_loss: 1.7430 - val_model_2_loss: 0.0067 - val_model_1_loss: 0.0622\n",
      "Epoch 19/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.8305 - model_2_loss: 0.0068 - model_1_loss: 0.1351 - val_loss: 1.7059 - val_model_2_loss: 0.0066 - val_model_1_loss: 0.0488\n",
      "Epoch 20/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.8010 - model_2_loss: 0.0067 - model_1_loss: 0.1354 - val_loss: 1.6659 - val_model_2_loss: 0.0065 - val_model_1_loss: 0.0499\n",
      "Epoch 21/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.7678 - model_2_loss: 0.0065 - model_1_loss: 0.1355 - val_loss: 1.6331 - val_model_2_loss: 0.0063 - val_model_1_loss: 0.0495\n",
      "Epoch 22/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.7349 - model_2_loss: 0.0064 - model_1_loss: 0.1285 - val_loss: 1.6072 - val_model_2_loss: 0.0062 - val_model_1_loss: 0.0449\n",
      "Epoch 23/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.7109 - model_2_loss: 0.0063 - model_1_loss: 0.1284 - val_loss: 1.6063 - val_model_2_loss: 0.0063 - val_model_1_loss: 0.0288\n",
      "Epoch 24/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.6848 - model_2_loss: 0.0062 - model_1_loss: 0.1262 - val_loss: 1.5514 - val_model_2_loss: 0.0060 - val_model_1_loss: 0.0511\n",
      "Epoch 25/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.6548 - model_2_loss: 0.0061 - model_1_loss: 0.1204 - val_loss: 1.5486 - val_model_2_loss: 0.0061 - val_model_1_loss: 0.0314\n",
      "Epoch 26/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.6420 - model_2_loss: 0.0061 - model_1_loss: 0.1202 - val_loss: 1.5234 - val_model_2_loss: 0.0059 - val_model_1_loss: 0.0369\n",
      "Epoch 27/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.6258 - model_2_loss: 0.0060 - model_1_loss: 0.1255 - val_loss: 1.5115 - val_model_2_loss: 0.0059 - val_model_1_loss: 0.0320\n",
      "Epoch 28/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.6055 - model_2_loss: 0.0059 - model_1_loss: 0.1199 - val_loss: 1.5050 - val_model_2_loss: 0.0059 - val_model_1_loss: 0.0246\n",
      "Epoch 29/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.5892 - model_2_loss: 0.0059 - model_1_loss: 0.1164 - val_loss: 1.4831 - val_model_2_loss: 0.0058 - val_model_1_loss: 0.0268\n",
      "Epoch 30/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.5753 - model_2_loss: 0.0058 - model_1_loss: 0.1161 - val_loss: 1.4983 - val_model_2_loss: 0.0059 - val_model_1_loss: 0.0163\n",
      "Epoch 31/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.5596 - model_2_loss: 0.0058 - model_1_loss: 0.1141 - val_loss: 1.4412 - val_model_2_loss: 0.0056 - val_model_1_loss: 0.0301\n",
      "Epoch 32/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.5480 - model_2_loss: 0.0057 - model_1_loss: 0.1156 - val_loss: 1.4335 - val_model_2_loss: 0.0056 - val_model_1_loss: 0.0258\n",
      "Epoch 33/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.5359 - model_2_loss: 0.0057 - model_1_loss: 0.1125 - val_loss: 1.4515 - val_model_2_loss: 0.0057 - val_model_1_loss: 0.0170\n",
      "Epoch 34/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.5241 - model_2_loss: 0.0056 - model_1_loss: 0.1132 - val_loss: 1.4242 - val_model_2_loss: 0.0056 - val_model_1_loss: 0.0210\n",
      "Epoch 35/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.5094 - model_2_loss: 0.0056 - model_1_loss: 0.1110 - val_loss: 1.4029 - val_model_2_loss: 0.0055 - val_model_1_loss: 0.0235\n",
      "Epoch 36/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.4998 - model_2_loss: 0.0056 - model_1_loss: 0.1118 - val_loss: 1.4032 - val_model_2_loss: 0.0055 - val_model_1_loss: 0.0186\n",
      "Epoch 37/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.4887 - model_2_loss: 0.0055 - model_1_loss: 0.1093 - val_loss: 1.4211 - val_model_2_loss: 0.0056 - val_model_1_loss: 0.0140\n",
      "Epoch 38/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.4744 - model_2_loss: 0.0055 - model_1_loss: 0.1089 - val_loss: 1.3653 - val_model_2_loss: 0.0053 - val_model_1_loss: 0.0301\n",
      "Epoch 39/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.4669 - model_2_loss: 0.0054 - model_1_loss: 0.1084 - val_loss: 1.3449 - val_model_2_loss: 0.0052 - val_model_1_loss: 0.0328\n",
      "Epoch 40/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.4566 - model_2_loss: 0.0054 - model_1_loss: 0.1103 - val_loss: 1.3595 - val_model_2_loss: 0.0054 - val_model_1_loss: 0.0215\n",
      "Epoch 41/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.4527 - model_2_loss: 0.0054 - model_1_loss: 0.1103 - val_loss: 1.3814 - val_model_2_loss: 0.0055 - val_model_1_loss: 0.0128\n",
      "Epoch 42/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.4446 - model_2_loss: 0.0053 - model_1_loss: 0.1084 - val_loss: 1.3539 - val_model_2_loss: 0.0054 - val_model_1_loss: 0.0161\n",
      "Epoch 43/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.4371 - model_2_loss: 0.0053 - model_1_loss: 0.1067 - val_loss: 1.3366 - val_model_2_loss: 0.0053 - val_model_1_loss: 0.0217\n",
      "Epoch 44/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.4263 - model_2_loss: 0.0053 - model_1_loss: 0.1057 - val_loss: 1.3154 - val_model_2_loss: 0.0051 - val_model_1_loss: 0.0298\n",
      "Epoch 45/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.4177 - model_2_loss: 0.0053 - model_1_loss: 0.1036 - val_loss: 1.3276 - val_model_2_loss: 0.0052 - val_model_1_loss: 0.0167\n",
      "Epoch 46/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.4111 - model_2_loss: 0.0052 - model_1_loss: 0.1032 - val_loss: 1.3631 - val_model_2_loss: 0.0054 - val_model_1_loss: 0.0080\n",
      "Epoch 47/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.4041 - model_2_loss: 0.0052 - model_1_loss: 0.1014 - val_loss: 1.3412 - val_model_2_loss: 0.0053 - val_model_1_loss: 0.0122\n",
      "Epoch 48/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3987 - model_2_loss: 0.0052 - model_1_loss: 0.1030 - val_loss: 1.3397 - val_model_2_loss: 0.0053 - val_model_1_loss: 0.0108\n",
      "Epoch 49/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3938 - model_2_loss: 0.0052 - model_1_loss: 0.0997 - val_loss: 1.2780 - val_model_2_loss: 0.0050 - val_model_1_loss: 0.0288\n",
      "Epoch 50/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3885 - model_2_loss: 0.0052 - model_1_loss: 0.1000 - val_loss: 1.3173 - val_model_2_loss: 0.0052 - val_model_1_loss: 0.0112\n",
      "Epoch 51/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3779 - model_2_loss: 0.0051 - model_1_loss: 0.0981 - val_loss: 1.3057 - val_model_2_loss: 0.0052 - val_model_1_loss: 0.0128\n",
      "Epoch 52/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3805 - model_2_loss: 0.0051 - model_1_loss: 0.1029 - val_loss: 1.2685 - val_model_2_loss: 0.0050 - val_model_1_loss: 0.0213\n",
      "Epoch 53/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3726 - model_2_loss: 0.0051 - model_1_loss: 0.1016 - val_loss: 1.2520 - val_model_2_loss: 0.0049 - val_model_1_loss: 0.0269\n",
      "Epoch 54/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3614 - model_2_loss: 0.0051 - model_1_loss: 0.0974 - val_loss: 1.2832 - val_model_2_loss: 0.0051 - val_model_1_loss: 0.0116\n",
      "Epoch 55/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3588 - model_2_loss: 0.0050 - model_1_loss: 0.0999 - val_loss: 1.2655 - val_model_2_loss: 0.0050 - val_model_1_loss: 0.0157\n",
      "Epoch 56/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3548 - model_2_loss: 0.0050 - model_1_loss: 0.0980 - val_loss: 1.2892 - val_model_2_loss: 0.0051 - val_model_1_loss: 0.0112\n",
      "Epoch 57/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3515 - model_2_loss: 0.0050 - model_1_loss: 0.1009 - val_loss: 1.2695 - val_model_2_loss: 0.0050 - val_model_1_loss: 0.0125\n",
      "Epoch 58/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3410 - model_2_loss: 0.0050 - model_1_loss: 0.0965 - val_loss: 1.2534 - val_model_2_loss: 0.0050 - val_model_1_loss: 0.0146\n",
      "Epoch 59/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3375 - model_2_loss: 0.0050 - model_1_loss: 0.0978 - val_loss: 1.2536 - val_model_2_loss: 0.0050 - val_model_1_loss: 0.0131\n",
      "Epoch 60/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3327 - model_2_loss: 0.0049 - model_1_loss: 0.0970 - val_loss: 1.2287 - val_model_2_loss: 0.0048 - val_model_1_loss: 0.0204\n",
      "Epoch 61/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3283 - model_2_loss: 0.0049 - model_1_loss: 0.0967 - val_loss: 1.2460 - val_model_2_loss: 0.0049 - val_model_1_loss: 0.0138\n",
      "Epoch 62/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3225 - model_2_loss: 0.0049 - model_1_loss: 0.0949 - val_loss: 1.2356 - val_model_2_loss: 0.0049 - val_model_1_loss: 0.0192\n",
      "Epoch 63/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3223 - model_2_loss: 0.0049 - model_1_loss: 0.0980 - val_loss: 1.2271 - val_model_2_loss: 0.0049 - val_model_1_loss: 0.0143\n",
      "Epoch 64/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3130 - model_2_loss: 0.0049 - model_1_loss: 0.0946 - val_loss: 1.2311 - val_model_2_loss: 0.0049 - val_model_1_loss: 0.0124\n",
      "Epoch 65/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3131 - model_2_loss: 0.0049 - model_1_loss: 0.0935 - val_loss: 1.2192 - val_model_2_loss: 0.0048 - val_model_1_loss: 0.0163\n",
      "Epoch 66/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3077 - model_2_loss: 0.0049 - model_1_loss: 0.0936 - val_loss: 1.2849 - val_model_2_loss: 0.0051 - val_model_1_loss: 0.0053\n",
      "Epoch 67/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.3034 - model_2_loss: 0.0048 - model_1_loss: 0.0918 - val_loss: 1.2015 - val_model_2_loss: 0.0047 - val_model_1_loss: 0.0180\n",
      "Epoch 68/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2945 - model_2_loss: 0.0048 - model_1_loss: 0.0919 - val_loss: 1.2286 - val_model_2_loss: 0.0049 - val_model_1_loss: 0.0093\n",
      "Epoch 69/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2980 - model_2_loss: 0.0048 - model_1_loss: 0.0931 - val_loss: 1.2179 - val_model_2_loss: 0.0048 - val_model_1_loss: 0.0122\n",
      "Epoch 70/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2919 - model_2_loss: 0.0048 - model_1_loss: 0.0920 - val_loss: 1.1921 - val_model_2_loss: 0.0047 - val_model_1_loss: 0.0165\n",
      "Epoch 71/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2862 - model_2_loss: 0.0048 - model_1_loss: 0.0902 - val_loss: 1.1891 - val_model_2_loss: 0.0047 - val_model_1_loss: 0.0227\n",
      "Epoch 72/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2832 - model_2_loss: 0.0048 - model_1_loss: 0.0926 - val_loss: 1.2250 - val_model_2_loss: 0.0049 - val_model_1_loss: 0.0079\n",
      "Epoch 73/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2767 - model_2_loss: 0.0048 - model_1_loss: 0.0876 - val_loss: 1.1947 - val_model_2_loss: 0.0047 - val_model_1_loss: 0.0115\n",
      "Epoch 74/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2748 - model_2_loss: 0.0047 - model_1_loss: 0.0911 - val_loss: 1.2906 - val_model_2_loss: 0.0051 - val_model_1_loss: 0.0041\n",
      "Epoch 75/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2810 - model_2_loss: 0.0048 - model_1_loss: 0.0910 - val_loss: 1.2257 - val_model_2_loss: 0.0049 - val_model_1_loss: 0.0064\n",
      "Epoch 76/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2703 - model_2_loss: 0.0047 - model_1_loss: 0.0905 - val_loss: 1.2320 - val_model_2_loss: 0.0049 - val_model_1_loss: 0.0063\n",
      "Epoch 77/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2656 - model_2_loss: 0.0047 - model_1_loss: 0.0909 - val_loss: 1.2301 - val_model_2_loss: 0.0049 - val_model_1_loss: 0.0064\n",
      "Epoch 78/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2644 - model_2_loss: 0.0047 - model_1_loss: 0.0906 - val_loss: 1.1576 - val_model_2_loss: 0.0045 - val_model_1_loss: 0.0236\n",
      "Epoch 79/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2576 - model_2_loss: 0.0047 - model_1_loss: 0.0903 - val_loss: 1.1864 - val_model_2_loss: 0.0047 - val_model_1_loss: 0.0139\n",
      "Epoch 80/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2582 - model_2_loss: 0.0047 - model_1_loss: 0.0909 - val_loss: 1.1668 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0155\n",
      "Epoch 81/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2522 - model_2_loss: 0.0047 - model_1_loss: 0.0893 - val_loss: 1.2218 - val_model_2_loss: 0.0049 - val_model_1_loss: 0.0067\n",
      "Epoch 82/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 1.2552 - model_2_loss: 0.0047 - model_1_loss: 0.0896 - val_loss: 1.1533 - val_model_2_loss: 0.0045 - val_model_1_loss: 0.0179\n",
      "Epoch 83/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2487 - model_2_loss: 0.0046 - model_1_loss: 0.0897 - val_loss: 1.1867 - val_model_2_loss: 0.0047 - val_model_1_loss: 0.0082\n",
      "Epoch 84/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2457 - model_2_loss: 0.0046 - model_1_loss: 0.0884 - val_loss: 1.1628 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0148\n",
      "Epoch 85/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2422 - model_2_loss: 0.0046 - model_1_loss: 0.0866 - val_loss: 1.1542 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0136\n",
      "Epoch 86/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2408 - model_2_loss: 0.0046 - model_1_loss: 0.0866 - val_loss: 1.1600 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0130\n",
      "Epoch 87/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2363 - model_2_loss: 0.0046 - model_1_loss: 0.0874 - val_loss: 1.1653 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0098\n",
      "Epoch 88/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2319 - model_2_loss: 0.0046 - model_1_loss: 0.0861 - val_loss: 1.1910 - val_model_2_loss: 0.0047 - val_model_1_loss: 0.0060\n",
      "Epoch 89/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2315 - model_2_loss: 0.0046 - model_1_loss: 0.0865 - val_loss: 1.1304 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0192\n",
      "Epoch 90/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2285 - model_2_loss: 0.0046 - model_1_loss: 0.0850 - val_loss: 1.1376 - val_model_2_loss: 0.0045 - val_model_1_loss: 0.0143\n",
      "Epoch 91/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2294 - model_2_loss: 0.0046 - model_1_loss: 0.0890 - val_loss: 1.1521 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0108\n",
      "Epoch 92/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2271 - model_2_loss: 0.0046 - model_1_loss: 0.0852 - val_loss: 1.1631 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0084\n",
      "Epoch 93/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2225 - model_2_loss: 0.0045 - model_1_loss: 0.0866 - val_loss: 1.2024 - val_model_2_loss: 0.0048 - val_model_1_loss: 0.0040\n",
      "Epoch 94/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2253 - model_2_loss: 0.0045 - model_1_loss: 0.0879 - val_loss: 1.1201 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0176\n",
      "Epoch 95/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2229 - model_2_loss: 0.0045 - model_1_loss: 0.0881 - val_loss: 1.1621 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0070\n",
      "Epoch 96/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2130 - model_2_loss: 0.0045 - model_1_loss: 0.0859 - val_loss: 1.1297 - val_model_2_loss: 0.0045 - val_model_1_loss: 0.0131\n",
      "Epoch 97/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2155 - model_2_loss: 0.0045 - model_1_loss: 0.0865 - val_loss: 1.1485 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0084\n",
      "Epoch 98/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2127 - model_2_loss: 0.0045 - model_1_loss: 0.0845 - val_loss: 1.1467 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0077\n",
      "Epoch 99/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2112 - model_2_loss: 0.0045 - model_1_loss: 0.0871 - val_loss: 1.1254 - val_model_2_loss: 0.0045 - val_model_1_loss: 0.0125\n",
      "Epoch 100/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2053 - model_2_loss: 0.0045 - model_1_loss: 0.0834 - val_loss: 1.1357 - val_model_2_loss: 0.0045 - val_model_1_loss: 0.0101\n",
      "Epoch 101/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2027 - model_2_loss: 0.0045 - model_1_loss: 0.0850 - val_loss: 1.1609 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0070\n",
      "Epoch 102/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2020 - model_2_loss: 0.0045 - model_1_loss: 0.0841 - val_loss: 1.1658 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0054\n",
      "Epoch 103/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2051 - model_2_loss: 0.0045 - model_1_loss: 0.0843 - val_loss: 1.1712 - val_model_2_loss: 0.0047 - val_model_1_loss: 0.0056\n",
      "Epoch 104/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.2027 - model_2_loss: 0.0045 - model_1_loss: 0.0863 - val_loss: 1.1716 - val_model_2_loss: 0.0047 - val_model_1_loss: 0.0051\n",
      "Epoch 105/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1997 - model_2_loss: 0.0045 - model_1_loss: 0.0857 - val_loss: 1.1475 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0067\n",
      "Epoch 106/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1976 - model_2_loss: 0.0044 - model_1_loss: 0.0857 - val_loss: 1.1526 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0062\n",
      "Epoch 107/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1957 - model_2_loss: 0.0045 - model_1_loss: 0.0824 - val_loss: 1.1624 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0054\n",
      "Epoch 108/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1928 - model_2_loss: 0.0044 - model_1_loss: 0.0821 - val_loss: 1.1645 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0058\n",
      "Epoch 109/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1916 - model_2_loss: 0.0044 - model_1_loss: 0.0831 - val_loss: 1.1328 - val_model_2_loss: 0.0045 - val_model_1_loss: 0.0074\n",
      "Epoch 110/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1867 - model_2_loss: 0.0044 - model_1_loss: 0.0809 - val_loss: 1.1668 - val_model_2_loss: 0.0046 - val_model_1_loss: 0.0045\n",
      "Epoch 111/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1906 - model_2_loss: 0.0044 - model_1_loss: 0.0838 - val_loss: 1.1197 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0081\n",
      "Epoch 112/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1853 - model_2_loss: 0.0044 - model_1_loss: 0.0817 - val_loss: 1.1148 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0088\n",
      "Epoch 113/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1862 - model_2_loss: 0.0044 - model_1_loss: 0.0855 - val_loss: 1.0952 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0151\n",
      "Epoch 114/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1819 - model_2_loss: 0.0044 - model_1_loss: 0.0825 - val_loss: 1.1027 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0120\n",
      "Epoch 115/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1835 - model_2_loss: 0.0044 - model_1_loss: 0.0842 - val_loss: 1.1010 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0133\n",
      "Epoch 116/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1788 - model_2_loss: 0.0044 - model_1_loss: 0.0822 - val_loss: 1.0780 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0270\n",
      "Epoch 117/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1761 - model_2_loss: 0.0044 - model_1_loss: 0.0820 - val_loss: 1.1047 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0119\n",
      "Epoch 118/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1725 - model_2_loss: 0.0044 - model_1_loss: 0.0827 - val_loss: 1.1012 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0103\n",
      "Epoch 119/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1747 - model_2_loss: 0.0044 - model_1_loss: 0.0833 - val_loss: 1.1022 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0106\n",
      "Epoch 120/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1714 - model_2_loss: 0.0044 - model_1_loss: 0.0818 - val_loss: 1.1050 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0092\n",
      "Epoch 121/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1686 - model_2_loss: 0.0044 - model_1_loss: 0.0791 - val_loss: 1.0837 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0138\n",
      "Epoch 122/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1651 - model_2_loss: 0.0043 - model_1_loss: 0.0809 - val_loss: 1.0848 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0138\n",
      "Epoch 123/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1699 - model_2_loss: 0.0043 - model_1_loss: 0.0849 - val_loss: 1.1240 - val_model_2_loss: 0.0045 - val_model_1_loss: 0.0071\n",
      "Epoch 124/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1687 - model_2_loss: 0.0043 - model_1_loss: 0.0823 - val_loss: 1.0962 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0089\n",
      "Epoch 125/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1636 - model_2_loss: 0.0043 - model_1_loss: 0.0797 - val_loss: 1.1169 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0070\n",
      "Epoch 126/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1587 - model_2_loss: 0.0043 - model_1_loss: 0.0809 - val_loss: 1.0834 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0118\n",
      "Epoch 127/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1629 - model_2_loss: 0.0043 - model_1_loss: 0.0823 - val_loss: 1.0896 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0087\n",
      "Epoch 128/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1583 - model_2_loss: 0.0043 - model_1_loss: 0.0813 - val_loss: 1.0973 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0089\n",
      "Epoch 129/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1568 - model_2_loss: 0.0043 - model_1_loss: 0.0792 - val_loss: 1.0755 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0161\n",
      "Epoch 130/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1590 - model_2_loss: 0.0043 - model_1_loss: 0.0821 - val_loss: 1.0847 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0095\n",
      "Epoch 131/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1538 - model_2_loss: 0.0043 - model_1_loss: 0.0809 - val_loss: 1.0699 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0164\n",
      "Epoch 132/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1549 - model_2_loss: 0.0043 - model_1_loss: 0.0808 - val_loss: 1.0758 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0179\n",
      "Epoch 133/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1514 - model_2_loss: 0.0043 - model_1_loss: 0.0790 - val_loss: 1.0860 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0094\n",
      "Epoch 134/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1519 - model_2_loss: 0.0043 - model_1_loss: 0.0800 - val_loss: 1.0787 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0119\n",
      "Epoch 135/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1481 - model_2_loss: 0.0043 - model_1_loss: 0.0783 - val_loss: 1.1347 - val_model_2_loss: 0.0045 - val_model_1_loss: 0.0038\n",
      "Epoch 136/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1467 - model_2_loss: 0.0043 - model_1_loss: 0.0789 - val_loss: 1.0841 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0074\n",
      "Epoch 137/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1501 - model_2_loss: 0.0043 - model_1_loss: 0.0808 - val_loss: 1.0676 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0124\n",
      "Epoch 138/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1475 - model_2_loss: 0.0043 - model_1_loss: 0.0819 - val_loss: 1.0861 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0082\n",
      "Epoch 139/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1475 - model_2_loss: 0.0043 - model_1_loss: 0.0790 - val_loss: 1.0718 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0117\n",
      "Epoch 140/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1436 - model_2_loss: 0.0042 - model_1_loss: 0.0822 - val_loss: 1.0632 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0118\n",
      "Epoch 141/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1416 - model_2_loss: 0.0043 - model_1_loss: 0.0774 - val_loss: 1.0463 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0172\n",
      "Epoch 142/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1386 - model_2_loss: 0.0042 - model_1_loss: 0.0792 - val_loss: 1.0506 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0147\n",
      "Epoch 143/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1403 - model_2_loss: 0.0042 - model_1_loss: 0.0788 - val_loss: 1.0625 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0143\n",
      "Epoch 144/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1398 - model_2_loss: 0.0042 - model_1_loss: 0.0817 - val_loss: 1.0648 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0103\n",
      "Epoch 145/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1372 - model_2_loss: 0.0042 - model_1_loss: 0.0800 - val_loss: 1.0666 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0093\n",
      "Epoch 146/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1378 - model_2_loss: 0.0042 - model_1_loss: 0.0781 - val_loss: 1.0622 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0120\n",
      "Epoch 147/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1382 - model_2_loss: 0.0042 - model_1_loss: 0.0809 - val_loss: 1.0400 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0246\n",
      "Epoch 148/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1371 - model_2_loss: 0.0042 - model_1_loss: 0.0812 - val_loss: 1.0616 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0102\n",
      "Epoch 149/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1344 - model_2_loss: 0.0042 - model_1_loss: 0.0822 - val_loss: 1.0699 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0078\n",
      "Epoch 150/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1351 - model_2_loss: 0.0042 - model_1_loss: 0.0796 - val_loss: 1.1129 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0043\n",
      "Epoch 151/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1321 - model_2_loss: 0.0042 - model_1_loss: 0.0790 - val_loss: 1.0448 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0136\n",
      "Epoch 152/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1311 - model_2_loss: 0.0042 - model_1_loss: 0.0785 - val_loss: 1.0566 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0099\n",
      "Epoch 153/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1285 - model_2_loss: 0.0042 - model_1_loss: 0.0792 - val_loss: 1.0852 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0054\n",
      "Epoch 154/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1260 - model_2_loss: 0.0042 - model_1_loss: 0.0778 - val_loss: 1.0816 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0065\n",
      "Epoch 155/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1316 - model_2_loss: 0.0042 - model_1_loss: 0.0792 - val_loss: 1.0591 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0084\n",
      "Epoch 156/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1221 - model_2_loss: 0.0042 - model_1_loss: 0.0758 - val_loss: 1.0514 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0098\n",
      "Epoch 157/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1234 - model_2_loss: 0.0042 - model_1_loss: 0.0776 - val_loss: 1.0693 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0067\n",
      "Epoch 158/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1235 - model_2_loss: 0.0042 - model_1_loss: 0.0797 - val_loss: 1.0354 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0129\n",
      "Epoch 159/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1219 - model_2_loss: 0.0042 - model_1_loss: 0.0777 - val_loss: 1.0433 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0114\n",
      "Epoch 160/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1177 - model_2_loss: 0.0042 - model_1_loss: 0.0769 - val_loss: 1.0676 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0074\n",
      "Epoch 161/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1216 - model_2_loss: 0.0042 - model_1_loss: 0.0787 - val_loss: 1.0348 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0133\n",
      "Epoch 162/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1176 - model_2_loss: 0.0042 - model_1_loss: 0.0776 - val_loss: 1.0425 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0109\n",
      "Epoch 163/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1157 - model_2_loss: 0.0042 - model_1_loss: 0.0748 - val_loss: 1.0582 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0080\n",
      "Epoch 164/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 1.1135 - model_2_loss: 0.0041 - model_1_loss: 0.0769 - val_loss: 1.0629 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0066\n",
      "Epoch 165/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1162 - model_2_loss: 0.0042 - model_1_loss: 0.0783 - val_loss: 1.0569 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0071\n",
      "Epoch 166/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1154 - model_2_loss: 0.0042 - model_1_loss: 0.0771 - val_loss: 1.0498 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0113\n",
      "Epoch 167/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1125 - model_2_loss: 0.0041 - model_1_loss: 0.0786 - val_loss: 1.0704 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0058\n",
      "Epoch 168/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1158 - model_2_loss: 0.0042 - model_1_loss: 0.0782 - val_loss: 1.0791 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0051\n",
      "Epoch 169/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1112 - model_2_loss: 0.0041 - model_1_loss: 0.0749 - val_loss: 1.0567 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0072\n",
      "Epoch 170/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1111 - model_2_loss: 0.0041 - model_1_loss: 0.0775 - val_loss: 1.0341 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0112\n",
      "Epoch 171/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1153 - model_2_loss: 0.0041 - model_1_loss: 0.0790 - val_loss: 1.0165 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0184\n",
      "Epoch 172/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1085 - model_2_loss: 0.0041 - model_1_loss: 0.0772 - val_loss: 1.0399 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0090\n",
      "Epoch 173/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1111 - model_2_loss: 0.0041 - model_1_loss: 0.0795 - val_loss: 1.0592 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0062\n",
      "Epoch 174/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1055 - model_2_loss: 0.0041 - model_1_loss: 0.0770 - val_loss: 1.0906 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0034\n",
      "Epoch 175/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1100 - model_2_loss: 0.0041 - model_1_loss: 0.0767 - val_loss: 1.0310 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0095\n",
      "Epoch 176/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1063 - model_2_loss: 0.0041 - model_1_loss: 0.0775 - val_loss: 1.0607 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0067\n",
      "Epoch 177/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1049 - model_2_loss: 0.0041 - model_1_loss: 0.0791 - val_loss: 1.0817 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0039\n",
      "Epoch 178/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1038 - model_2_loss: 0.0041 - model_1_loss: 0.0769 - val_loss: 1.0340 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0084\n",
      "Epoch 179/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1021 - model_2_loss: 0.0041 - model_1_loss: 0.0750 - val_loss: 1.0000 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0257\n",
      "Epoch 180/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1054 - model_2_loss: 0.0041 - model_1_loss: 0.0787 - val_loss: 1.0964 - val_model_2_loss: 0.0044 - val_model_1_loss: 0.0031\n",
      "Epoch 181/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1017 - model_2_loss: 0.0041 - model_1_loss: 0.0753 - val_loss: 1.0708 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0057\n",
      "Epoch 182/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1068 - model_2_loss: 0.0041 - model_1_loss: 0.0769 - val_loss: 1.0859 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0033\n",
      "Epoch 183/1000\n",
      "50000/50000 [==============================] - 37s - loss: 1.1006 - model_2_loss: 0.0041 - model_1_loss: 0.0765 - val_loss: 1.0723 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0046\n",
      "Epoch 184/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1008 - model_2_loss: 0.0041 - model_1_loss: 0.0774 - val_loss: 1.0785 - val_model_2_loss: 0.0043 - val_model_1_loss: 0.0042\n",
      "Epoch 185/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.1025 - model_2_loss: 0.0041 - model_1_loss: 0.0775 - val_loss: 1.0390 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0072\n",
      "Epoch 186/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0998 - model_2_loss: 0.0041 - model_1_loss: 0.0765 - val_loss: 1.0542 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0061\n",
      "Epoch 187/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0954 - model_2_loss: 0.0041 - model_1_loss: 0.0750 - val_loss: 1.0324 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0078\n",
      "Epoch 188/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0905 - model_2_loss: 0.0041 - model_1_loss: 0.0744 - val_loss: 1.0397 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0065\n",
      "Epoch 189/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0955 - model_2_loss: 0.0041 - model_1_loss: 0.0781 - val_loss: 1.0385 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0072\n",
      "Epoch 190/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0979 - model_2_loss: 0.0041 - model_1_loss: 0.0748 - val_loss: 1.0241 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0098\n",
      "Epoch 191/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0930 - model_2_loss: 0.0041 - model_1_loss: 0.0746 - val_loss: 1.0207 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0123\n",
      "Epoch 192/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0935 - model_2_loss: 0.0041 - model_1_loss: 0.0774 - val_loss: 1.0489 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0057\n",
      "Epoch 193/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0922 - model_2_loss: 0.0041 - model_1_loss: 0.0759 - val_loss: 1.0519 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0044\n",
      "Epoch 194/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0895 - model_2_loss: 0.0041 - model_1_loss: 0.0738 - val_loss: 1.0227 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0084\n",
      "Epoch 195/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0939 - model_2_loss: 0.0041 - model_1_loss: 0.0772 - val_loss: 1.0322 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0077\n",
      "Epoch 196/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0910 - model_2_loss: 0.0041 - model_1_loss: 0.0736 - val_loss: 1.0187 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0087\n",
      "Epoch 197/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0902 - model_2_loss: 0.0040 - model_1_loss: 0.0782 - val_loss: 1.0423 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0053\n",
      "Epoch 198/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0871 - model_2_loss: 0.0041 - model_1_loss: 0.0736 - val_loss: 1.0391 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0061\n",
      "Epoch 199/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0844 - model_2_loss: 0.0040 - model_1_loss: 0.0761 - val_loss: 1.0131 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0098\n",
      "Epoch 200/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0866 - model_2_loss: 0.0040 - model_1_loss: 0.0766 - val_loss: 1.0139 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0091\n",
      "Epoch 201/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0843 - model_2_loss: 0.0040 - model_1_loss: 0.0760 - val_loss: 1.0335 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0070\n",
      "Epoch 202/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0828 - model_2_loss: 0.0040 - model_1_loss: 0.0736 - val_loss: 1.0587 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0041\n",
      "Epoch 203/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0844 - model_2_loss: 0.0040 - model_1_loss: 0.0762 - val_loss: 1.0389 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0050\n",
      "Epoch 204/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0884 - model_2_loss: 0.0041 - model_1_loss: 0.0754 - val_loss: 1.0149 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0085\n",
      "Epoch 205/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 1.0775 - model_2_loss: 0.0040 - model_1_loss: 0.0726 - val_loss: 1.0008 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0108\n",
      "Epoch 206/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0805 - model_2_loss: 0.0040 - model_1_loss: 0.0744 - val_loss: 1.0113 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0095\n",
      "Epoch 207/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0829 - model_2_loss: 0.0040 - model_1_loss: 0.0750 - val_loss: 1.0142 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0083\n",
      "Epoch 208/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0785 - model_2_loss: 0.0040 - model_1_loss: 0.0747 - val_loss: 1.0553 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0051\n",
      "Epoch 209/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0804 - model_2_loss: 0.0040 - model_1_loss: 0.0741 - val_loss: 0.9923 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0123\n",
      "Epoch 210/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0803 - model_2_loss: 0.0040 - model_1_loss: 0.0761 - val_loss: 1.0147 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0074\n",
      "Epoch 211/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0777 - model_2_loss: 0.0040 - model_1_loss: 0.0749 - val_loss: 1.0051 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0096\n",
      "Epoch 212/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0796 - model_2_loss: 0.0040 - model_1_loss: 0.0741 - val_loss: 1.0138 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0080\n",
      "Epoch 213/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0709 - model_2_loss: 0.0040 - model_1_loss: 0.0728 - val_loss: 1.0366 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0042\n",
      "Epoch 214/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0773 - model_2_loss: 0.0040 - model_1_loss: 0.0729 - val_loss: 1.0276 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0048\n",
      "Epoch 215/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0726 - model_2_loss: 0.0040 - model_1_loss: 0.0727 - val_loss: 1.0144 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0074\n",
      "Epoch 216/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0754 - model_2_loss: 0.0040 - model_1_loss: 0.0756 - val_loss: 1.0451 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0038\n",
      "Epoch 217/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0714 - model_2_loss: 0.0040 - model_1_loss: 0.0710 - val_loss: 0.9900 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0120\n",
      "Epoch 218/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0736 - model_2_loss: 0.0040 - model_1_loss: 0.0759 - val_loss: 1.0028 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0073\n",
      "Epoch 219/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0731 - model_2_loss: 0.0040 - model_1_loss: 0.0744 - val_loss: 0.9906 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0135\n",
      "Epoch 220/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0741 - model_2_loss: 0.0040 - model_1_loss: 0.0737 - val_loss: 1.0355 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0045\n",
      "Epoch 221/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0684 - model_2_loss: 0.0040 - model_1_loss: 0.0724 - val_loss: 0.9947 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0097\n",
      "Epoch 222/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0731 - model_2_loss: 0.0040 - model_1_loss: 0.0737 - val_loss: 0.9812 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0133\n",
      "Epoch 223/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0690 - model_2_loss: 0.0040 - model_1_loss: 0.0736 - val_loss: 1.0154 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0057\n",
      "Epoch 224/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0688 - model_2_loss: 0.0040 - model_1_loss: 0.0717 - val_loss: 0.9920 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0113\n",
      "Epoch 225/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0697 - model_2_loss: 0.0040 - model_1_loss: 0.0730 - val_loss: 1.0255 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0059\n",
      "Epoch 226/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0706 - model_2_loss: 0.0040 - model_1_loss: 0.0731 - val_loss: 0.9912 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0101\n",
      "Epoch 227/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0719 - model_2_loss: 0.0040 - model_1_loss: 0.0777 - val_loss: 0.9968 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0081\n",
      "Epoch 228/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0682 - model_2_loss: 0.0040 - model_1_loss: 0.0727 - val_loss: 1.0270 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0043\n",
      "Epoch 229/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0655 - model_2_loss: 0.0040 - model_1_loss: 0.0735 - val_loss: 0.9853 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0101\n",
      "Epoch 230/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0603 - model_2_loss: 0.0040 - model_1_loss: 0.0705 - val_loss: 0.9836 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0134\n",
      "Epoch 231/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0640 - model_2_loss: 0.0040 - model_1_loss: 0.0723 - val_loss: 1.0114 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0060\n",
      "Epoch 232/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0634 - model_2_loss: 0.0040 - model_1_loss: 0.0728 - val_loss: 1.0019 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0070\n",
      "Epoch 233/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0659 - model_2_loss: 0.0040 - model_1_loss: 0.0742 - val_loss: 1.0008 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0078\n",
      "Epoch 234/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0660 - model_2_loss: 0.0040 - model_1_loss: 0.0765 - val_loss: 0.9882 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0126\n",
      "Epoch 235/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0664 - model_2_loss: 0.0040 - model_1_loss: 0.0742 - val_loss: 1.0135 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0053\n",
      "Epoch 236/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0644 - model_2_loss: 0.0040 - model_1_loss: 0.0732 - val_loss: 1.0096 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0054\n",
      "Epoch 237/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0585 - model_2_loss: 0.0039 - model_1_loss: 0.0710 - val_loss: 0.9953 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0078\n",
      "Epoch 238/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0625 - model_2_loss: 0.0040 - model_1_loss: 0.0748 - val_loss: 1.0011 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0074\n",
      "Epoch 239/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0613 - model_2_loss: 0.0040 - model_1_loss: 0.0735 - val_loss: 0.9984 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0066\n",
      "Epoch 240/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0595 - model_2_loss: 0.0039 - model_1_loss: 0.0734 - val_loss: 1.0145 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0052\n",
      "Epoch 241/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0595 - model_2_loss: 0.0039 - model_1_loss: 0.0734 - val_loss: 0.9933 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0074\n",
      "Epoch 242/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0572 - model_2_loss: 0.0039 - model_1_loss: 0.0721 - val_loss: 0.9986 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0073\n",
      "Epoch 243/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0599 - model_2_loss: 0.0040 - model_1_loss: 0.0711 - val_loss: 0.9898 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0076\n",
      "Epoch 244/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0553 - model_2_loss: 0.0039 - model_1_loss: 0.0712 - val_loss: 0.9710 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0120\n",
      "Epoch 245/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0567 - model_2_loss: 0.0039 - model_1_loss: 0.0743 - val_loss: 1.0052 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0049\n",
      "Epoch 246/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 1.0573 - model_2_loss: 0.0039 - model_1_loss: 0.0726 - val_loss: 1.0099 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0048\n",
      "Epoch 247/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0551 - model_2_loss: 0.0039 - model_1_loss: 0.0727 - val_loss: 1.0076 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0047\n",
      "Epoch 248/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0546 - model_2_loss: 0.0039 - model_1_loss: 0.0720 - val_loss: 0.9992 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0062\n",
      "Epoch 249/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0503 - model_2_loss: 0.0039 - model_1_loss: 0.0694 - val_loss: 0.9992 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0061\n",
      "Epoch 250/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0557 - model_2_loss: 0.0039 - model_1_loss: 0.0729 - val_loss: 0.9732 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0229\n",
      "Epoch 251/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0533 - model_2_loss: 0.0039 - model_1_loss: 0.0723 - val_loss: 0.9995 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0054\n",
      "Epoch 252/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0499 - model_2_loss: 0.0039 - model_1_loss: 0.0713 - val_loss: 0.9934 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0068\n",
      "Epoch 253/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0509 - model_2_loss: 0.0039 - model_1_loss: 0.0710 - val_loss: 0.9680 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0145\n",
      "Epoch 254/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0493 - model_2_loss: 0.0039 - model_1_loss: 0.0709 - val_loss: 0.9960 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0070\n",
      "Epoch 255/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0553 - model_2_loss: 0.0039 - model_1_loss: 0.0747 - val_loss: 1.0131 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0040\n",
      "Epoch 256/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0546 - model_2_loss: 0.0039 - model_1_loss: 0.0724 - val_loss: 0.9800 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0081\n",
      "Epoch 257/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0510 - model_2_loss: 0.0039 - model_1_loss: 0.0730 - val_loss: 0.9897 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0063\n",
      "Epoch 258/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0444 - model_2_loss: 0.0039 - model_1_loss: 0.0696 - val_loss: 0.9988 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0050\n",
      "Epoch 259/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0506 - model_2_loss: 0.0039 - model_1_loss: 0.0747 - val_loss: 1.0241 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0038\n",
      "Epoch 260/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0469 - model_2_loss: 0.0039 - model_1_loss: 0.0723 - val_loss: 1.0027 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0063\n",
      "Epoch 261/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0479 - model_2_loss: 0.0039 - model_1_loss: 0.0723 - val_loss: 1.0058 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0047\n",
      "Epoch 262/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0452 - model_2_loss: 0.0039 - model_1_loss: 0.0728 - val_loss: 0.9902 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0055\n",
      "Epoch 263/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0477 - model_2_loss: 0.0039 - model_1_loss: 0.0716 - val_loss: 0.9905 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0055\n",
      "Epoch 264/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0476 - model_2_loss: 0.0039 - model_1_loss: 0.0722 - val_loss: 0.9626 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0115\n",
      "Epoch 265/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0457 - model_2_loss: 0.0039 - model_1_loss: 0.0732 - val_loss: 0.9852 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0062\n",
      "Epoch 266/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0427 - model_2_loss: 0.0039 - model_1_loss: 0.0703 - val_loss: 0.9946 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0055\n",
      "Epoch 267/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0427 - model_2_loss: 0.0039 - model_1_loss: 0.0709 - val_loss: 0.9763 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0071\n",
      "Epoch 268/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0404 - model_2_loss: 0.0039 - model_1_loss: 0.0694 - val_loss: 1.0106 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0039\n",
      "Epoch 269/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0423 - model_2_loss: 0.0039 - model_1_loss: 0.0717 - val_loss: 1.0161 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0038\n",
      "Epoch 270/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0389 - model_2_loss: 0.0039 - model_1_loss: 0.0708 - val_loss: 0.9608 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0093\n",
      "Epoch 271/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0413 - model_2_loss: 0.0039 - model_1_loss: 0.0727 - val_loss: 1.0107 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0036\n",
      "Epoch 272/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0444 - model_2_loss: 0.0039 - model_1_loss: 0.0705 - val_loss: 0.9970 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0051\n",
      "Epoch 273/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0425 - model_2_loss: 0.0039 - model_1_loss: 0.0715 - val_loss: 0.9937 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0048\n",
      "Epoch 274/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0405 - model_2_loss: 0.0039 - model_1_loss: 0.0733 - val_loss: 1.0321 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0025\n",
      "Epoch 275/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0394 - model_2_loss: 0.0039 - model_1_loss: 0.0707 - val_loss: 0.9899 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0050\n",
      "Epoch 276/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0448 - model_2_loss: 0.0039 - model_1_loss: 0.0726 - val_loss: 0.9967 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0041\n",
      "Epoch 277/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0379 - model_2_loss: 0.0039 - model_1_loss: 0.0679 - val_loss: 0.9614 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0092\n",
      "Epoch 278/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0398 - model_2_loss: 0.0039 - model_1_loss: 0.0729 - val_loss: 1.0046 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0039\n",
      "Epoch 279/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0375 - model_2_loss: 0.0039 - model_1_loss: 0.0714 - val_loss: 0.9595 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0109\n",
      "Epoch 280/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0362 - model_2_loss: 0.0039 - model_1_loss: 0.0693 - val_loss: 0.9639 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0086\n",
      "Epoch 281/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0375 - model_2_loss: 0.0039 - model_1_loss: 0.0706 - val_loss: 0.9697 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0087\n",
      "Epoch 282/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0323 - model_2_loss: 0.0039 - model_1_loss: 0.0694 - val_loss: 0.9902 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0055\n",
      "Epoch 283/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0357 - model_2_loss: 0.0039 - model_1_loss: 0.0713 - val_loss: 0.9556 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0136\n",
      "Epoch 284/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0350 - model_2_loss: 0.0039 - model_1_loss: 0.0707 - val_loss: 0.9662 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0069\n",
      "Epoch 285/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0329 - model_2_loss: 0.0039 - model_1_loss: 0.0700 - val_loss: 0.9641 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0082\n",
      "Epoch 286/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0348 - model_2_loss: 0.0039 - model_1_loss: 0.0696 - val_loss: 0.9714 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0068\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 1.0307 - model_2_loss: 0.0038 - model_1_loss: 0.0688 - val_loss: 0.9485 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0117\n",
      "Epoch 288/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0322 - model_2_loss: 0.0038 - model_1_loss: 0.0704 - val_loss: 0.9818 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0047\n",
      "Epoch 289/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0327 - model_2_loss: 0.0039 - model_1_loss: 0.0701 - val_loss: 0.9551 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0080\n",
      "Epoch 290/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0325 - model_2_loss: 0.0039 - model_1_loss: 0.0691 - val_loss: 0.9716 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0061\n",
      "Epoch 291/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0331 - model_2_loss: 0.0038 - model_1_loss: 0.0729 - val_loss: 0.9685 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0068\n",
      "Epoch 292/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0301 - model_2_loss: 0.0038 - model_1_loss: 0.0694 - val_loss: 0.9727 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0056\n",
      "Epoch 293/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0288 - model_2_loss: 0.0038 - model_1_loss: 0.0698 - val_loss: 0.9373 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0148\n",
      "Epoch 294/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0289 - model_2_loss: 0.0038 - model_1_loss: 0.0703 - val_loss: 0.9748 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0048\n",
      "Epoch 295/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0269 - model_2_loss: 0.0038 - model_1_loss: 0.0699 - val_loss: 0.9687 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0071\n",
      "Epoch 296/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0286 - model_2_loss: 0.0038 - model_1_loss: 0.0698 - val_loss: 0.9821 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0048\n",
      "Epoch 297/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0299 - model_2_loss: 0.0038 - model_1_loss: 0.0722 - val_loss: 0.9501 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0099\n",
      "Epoch 298/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0295 - model_2_loss: 0.0038 - model_1_loss: 0.0727 - val_loss: 0.9885 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0039\n",
      "Epoch 299/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0281 - model_2_loss: 0.0038 - model_1_loss: 0.0711 - val_loss: 1.0435 - val_model_2_loss: 0.0042 - val_model_1_loss: 0.0018\n",
      "Epoch 300/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0264 - model_2_loss: 0.0038 - model_1_loss: 0.0700 - val_loss: 0.9583 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0071\n",
      "Epoch 301/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0236 - model_2_loss: 0.0038 - model_1_loss: 0.0679 - val_loss: 0.9595 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0079\n",
      "Epoch 302/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0290 - model_2_loss: 0.0038 - model_1_loss: 0.0711 - val_loss: 1.0153 - val_model_2_loss: 0.0041 - val_model_1_loss: 0.0026\n",
      "Epoch 303/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0231 - model_2_loss: 0.0038 - model_1_loss: 0.0697 - val_loss: 0.9678 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0049\n",
      "Epoch 304/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0270 - model_2_loss: 0.0038 - model_1_loss: 0.0711 - val_loss: 0.9655 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0065\n",
      "Epoch 305/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0220 - model_2_loss: 0.0038 - model_1_loss: 0.0685 - val_loss: 0.9718 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0049\n",
      "Epoch 306/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0224 - model_2_loss: 0.0038 - model_1_loss: 0.0681 - val_loss: 0.9711 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0042\n",
      "Epoch 307/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0206 - model_2_loss: 0.0038 - model_1_loss: 0.0691 - val_loss: 0.9468 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0086\n",
      "Epoch 308/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0219 - model_2_loss: 0.0038 - model_1_loss: 0.0683 - val_loss: 0.9504 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0077\n",
      "Epoch 309/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0251 - model_2_loss: 0.0038 - model_1_loss: 0.0714 - val_loss: 0.9528 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0071\n",
      "Epoch 310/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0263 - model_2_loss: 0.0038 - model_1_loss: 0.0735 - val_loss: 0.9392 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0115\n",
      "Epoch 311/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0217 - model_2_loss: 0.0038 - model_1_loss: 0.0701 - val_loss: 0.9778 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0046\n",
      "Epoch 312/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0211 - model_2_loss: 0.0038 - model_1_loss: 0.0696 - val_loss: 0.9728 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0039\n",
      "Epoch 313/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0217 - model_2_loss: 0.0038 - model_1_loss: 0.0697 - val_loss: 0.9537 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0075\n",
      "Epoch 314/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0238 - model_2_loss: 0.0038 - model_1_loss: 0.0672 - val_loss: 1.0031 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0021\n",
      "Epoch 315/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0232 - model_2_loss: 0.0038 - model_1_loss: 0.0709 - val_loss: 0.9716 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0045\n",
      "Epoch 316/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0212 - model_2_loss: 0.0038 - model_1_loss: 0.0697 - val_loss: 0.9605 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0053\n",
      "Epoch 317/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0188 - model_2_loss: 0.0038 - model_1_loss: 0.0700 - val_loss: 0.9447 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0071\n",
      "Epoch 318/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0206 - model_2_loss: 0.0038 - model_1_loss: 0.0692 - val_loss: 0.9573 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0060\n",
      "Epoch 319/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0208 - model_2_loss: 0.0038 - model_1_loss: 0.0707 - val_loss: 0.9374 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0092\n",
      "Epoch 320/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0163 - model_2_loss: 0.0038 - model_1_loss: 0.0700 - val_loss: 0.9573 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0053\n",
      "Epoch 321/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0164 - model_2_loss: 0.0038 - model_1_loss: 0.0679 - val_loss: 0.9535 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0060\n",
      "Epoch 322/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0150 - model_2_loss: 0.0038 - model_1_loss: 0.0693 - val_loss: 0.9694 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0045\n",
      "Epoch 323/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0152 - model_2_loss: 0.0038 - model_1_loss: 0.0707 - val_loss: 0.9575 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0049\n",
      "Epoch 324/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0164 - model_2_loss: 0.0038 - model_1_loss: 0.0699 - val_loss: 1.0050 - val_model_2_loss: 0.0040 - val_model_1_loss: 0.0020\n",
      "Epoch 325/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0125 - model_2_loss: 0.0038 - model_1_loss: 0.0681 - val_loss: 0.9765 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0033\n",
      "Epoch 326/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0134 - model_2_loss: 0.0038 - model_1_loss: 0.0680 - val_loss: 0.9256 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0135\n",
      "Epoch 327/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0201 - model_2_loss: 0.0038 - model_1_loss: 0.0712 - val_loss: 0.9263 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0122\n",
      "Epoch 328/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 1.0132 - model_2_loss: 0.0038 - model_1_loss: 0.0680 - val_loss: 0.9742 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0039\n",
      "Epoch 329/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0110 - model_2_loss: 0.0038 - model_1_loss: 0.0678 - val_loss: 0.9796 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0039\n",
      "Epoch 330/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0124 - model_2_loss: 0.0038 - model_1_loss: 0.0679 - val_loss: 0.9274 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0113\n",
      "Epoch 331/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0119 - model_2_loss: 0.0038 - model_1_loss: 0.0680 - val_loss: 0.9528 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0050\n",
      "Epoch 332/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0160 - model_2_loss: 0.0038 - model_1_loss: 0.0692 - val_loss: 0.9440 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0068\n",
      "Epoch 333/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0121 - model_2_loss: 0.0038 - model_1_loss: 0.0692 - val_loss: 0.9716 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0052\n",
      "Epoch 334/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0116 - model_2_loss: 0.0038 - model_1_loss: 0.0677 - val_loss: 0.9879 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0030\n",
      "Epoch 335/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0101 - model_2_loss: 0.0038 - model_1_loss: 0.0678 - val_loss: 0.9792 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0034\n",
      "Epoch 336/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0078 - model_2_loss: 0.0038 - model_1_loss: 0.0681 - val_loss: 0.9463 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0062\n",
      "Epoch 337/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0129 - model_2_loss: 0.0038 - model_1_loss: 0.0708 - val_loss: 0.9343 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0083\n",
      "Epoch 338/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0138 - model_2_loss: 0.0038 - model_1_loss: 0.0721 - val_loss: 0.9583 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0045\n",
      "Epoch 339/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0108 - model_2_loss: 0.0038 - model_1_loss: 0.0684 - val_loss: 0.9519 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0049\n",
      "Epoch 340/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0092 - model_2_loss: 0.0038 - model_1_loss: 0.0699 - val_loss: 0.9437 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0059\n",
      "Epoch 341/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0093 - model_2_loss: 0.0038 - model_1_loss: 0.0683 - val_loss: 0.9337 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0089\n",
      "Epoch 342/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0100 - model_2_loss: 0.0038 - model_1_loss: 0.0699 - val_loss: 0.9728 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0027\n",
      "Epoch 343/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0080 - model_2_loss: 0.0038 - model_1_loss: 0.0689 - val_loss: 0.9633 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0042\n",
      "Epoch 344/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0100 - model_2_loss: 0.0038 - model_1_loss: 0.0707 - val_loss: 0.9904 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0031\n",
      "Epoch 345/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0056 - model_2_loss: 0.0038 - model_1_loss: 0.0679 - val_loss: 0.9434 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0075\n",
      "Epoch 346/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0084 - model_2_loss: 0.0038 - model_1_loss: 0.0692 - val_loss: 0.9538 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0041\n",
      "Epoch 347/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0057 - model_2_loss: 0.0038 - model_1_loss: 0.0660 - val_loss: 0.9410 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0069\n",
      "Epoch 348/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0072 - model_2_loss: 0.0037 - model_1_loss: 0.0698 - val_loss: 0.9709 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0029\n",
      "Epoch 349/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0015 - model_2_loss: 0.0037 - model_1_loss: 0.0680 - val_loss: 0.9534 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0039\n",
      "Epoch 350/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0072 - model_2_loss: 0.0038 - model_1_loss: 0.0691 - val_loss: 0.9316 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0083\n",
      "Epoch 351/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0061 - model_2_loss: 0.0037 - model_1_loss: 0.0689 - val_loss: 0.9454 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0058\n",
      "Epoch 352/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0077 - model_2_loss: 0.0038 - model_1_loss: 0.0686 - val_loss: 0.9408 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0061\n",
      "Epoch 353/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0045 - model_2_loss: 0.0037 - model_1_loss: 0.0694 - val_loss: 0.9504 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0053\n",
      "Epoch 354/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0027 - model_2_loss: 0.0037 - model_1_loss: 0.0689 - val_loss: 0.9541 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0046\n",
      "Epoch 355/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0077 - model_2_loss: 0.0037 - model_1_loss: 0.0715 - val_loss: 0.9606 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0032\n",
      "Epoch 356/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0044 - model_2_loss: 0.0037 - model_1_loss: 0.0693 - val_loss: 0.9829 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0027\n",
      "Epoch 357/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0035 - model_2_loss: 0.0037 - model_1_loss: 0.0683 - val_loss: 0.9477 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0050\n",
      "Epoch 358/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9998 - model_2_loss: 0.0037 - model_1_loss: 0.0662 - val_loss: 0.9168 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0105\n",
      "Epoch 359/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0023 - model_2_loss: 0.0037 - model_1_loss: 0.0697 - val_loss: 0.9329 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0064\n",
      "Epoch 360/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0048 - model_2_loss: 0.0037 - model_1_loss: 0.0698 - val_loss: 0.9707 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0030\n",
      "Epoch 361/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0031 - model_2_loss: 0.0037 - model_1_loss: 0.0692 - val_loss: 0.9549 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0054\n",
      "Epoch 362/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0036 - model_2_loss: 0.0037 - model_1_loss: 0.0705 - val_loss: 0.9576 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0036\n",
      "Epoch 363/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0042 - model_2_loss: 0.0037 - model_1_loss: 0.0698 - val_loss: 0.9785 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0023\n",
      "Epoch 364/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9989 - model_2_loss: 0.0037 - model_1_loss: 0.0662 - val_loss: 0.9404 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0049\n",
      "Epoch 365/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0005 - model_2_loss: 0.0037 - model_1_loss: 0.0687 - val_loss: 0.9552 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0038\n",
      "Epoch 366/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9954 - model_2_loss: 0.0037 - model_1_loss: 0.0667 - val_loss: 0.9119 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0114\n",
      "Epoch 367/1000\n",
      "50000/50000 [==============================] - 38s - loss: 1.0002 - model_2_loss: 0.0037 - model_1_loss: 0.0680 - val_loss: 0.9413 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0048\n",
      "Epoch 368/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9975 - model_2_loss: 0.0037 - model_1_loss: 0.0675 - val_loss: 0.9457 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0036\n",
      "Epoch 369/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 0.9985 - model_2_loss: 0.0037 - model_1_loss: 0.0658 - val_loss: 0.9251 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0087\n",
      "Epoch 370/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9945 - model_2_loss: 0.0037 - model_1_loss: 0.0670 - val_loss: 0.9735 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0025\n",
      "Epoch 371/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9972 - model_2_loss: 0.0037 - model_1_loss: 0.0679 - val_loss: 0.9628 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0032\n",
      "Epoch 372/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9971 - model_2_loss: 0.0037 - model_1_loss: 0.0694 - val_loss: 0.9312 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0064\n",
      "Epoch 373/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9978 - model_2_loss: 0.0037 - model_1_loss: 0.0670 - val_loss: 0.9510 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0042\n",
      "Epoch 374/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9935 - model_2_loss: 0.0037 - model_1_loss: 0.0673 - val_loss: 0.9207 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0074\n",
      "Epoch 375/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9986 - model_2_loss: 0.0037 - model_1_loss: 0.0706 - val_loss: 0.9193 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0072\n",
      "Epoch 376/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9952 - model_2_loss: 0.0037 - model_1_loss: 0.0676 - val_loss: 0.9192 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0125\n",
      "Epoch 377/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9915 - model_2_loss: 0.0037 - model_1_loss: 0.0662 - val_loss: 0.9243 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0060\n",
      "Epoch 378/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9947 - model_2_loss: 0.0037 - model_1_loss: 0.0671 - val_loss: 0.9222 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0073\n",
      "Epoch 379/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9922 - model_2_loss: 0.0037 - model_1_loss: 0.0667 - val_loss: 0.9477 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0035\n",
      "Epoch 380/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9876 - model_2_loss: 0.0037 - model_1_loss: 0.0641 - val_loss: 0.9216 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0065\n",
      "Epoch 381/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9916 - model_2_loss: 0.0037 - model_1_loss: 0.0669 - val_loss: 0.9236 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0059\n",
      "Epoch 382/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9911 - model_2_loss: 0.0037 - model_1_loss: 0.0676 - val_loss: 0.9273 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0050\n",
      "Epoch 383/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9925 - model_2_loss: 0.0037 - model_1_loss: 0.0656 - val_loss: 0.9077 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0096\n",
      "Epoch 384/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9915 - model_2_loss: 0.0037 - model_1_loss: 0.0678 - val_loss: 0.9275 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0050\n",
      "Epoch 385/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9868 - model_2_loss: 0.0037 - model_1_loss: 0.0666 - val_loss: 0.9279 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0055\n",
      "Epoch 386/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9926 - model_2_loss: 0.0037 - model_1_loss: 0.0674 - val_loss: 0.9216 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0064\n",
      "Epoch 387/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9893 - model_2_loss: 0.0037 - model_1_loss: 0.0665 - val_loss: 0.9250 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0057\n",
      "Epoch 388/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9910 - model_2_loss: 0.0037 - model_1_loss: 0.0677 - val_loss: 0.9038 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0115\n",
      "Epoch 389/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9949 - model_2_loss: 0.0037 - model_1_loss: 0.0675 - val_loss: 0.9439 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0037\n",
      "Epoch 390/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9892 - model_2_loss: 0.0037 - model_1_loss: 0.0682 - val_loss: 0.9137 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0074\n",
      "Epoch 391/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9907 - model_2_loss: 0.0037 - model_1_loss: 0.0690 - val_loss: 0.9555 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0026\n",
      "Epoch 392/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9947 - model_2_loss: 0.0037 - model_1_loss: 0.0683 - val_loss: 0.9130 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0073\n",
      "Epoch 393/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9871 - model_2_loss: 0.0037 - model_1_loss: 0.0659 - val_loss: 0.9485 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0034\n",
      "Epoch 394/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9896 - model_2_loss: 0.0037 - model_1_loss: 0.0681 - val_loss: 0.9200 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0068\n",
      "Epoch 395/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9884 - model_2_loss: 0.0037 - model_1_loss: 0.0674 - val_loss: 0.9373 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0036\n",
      "Epoch 396/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9866 - model_2_loss: 0.0037 - model_1_loss: 0.0672 - val_loss: 0.9887 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0013\n",
      "Epoch 397/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9881 - model_2_loss: 0.0037 - model_1_loss: 0.0683 - val_loss: 0.9221 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0064\n",
      "Epoch 398/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9864 - model_2_loss: 0.0037 - model_1_loss: 0.0671 - val_loss: 0.9598 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0027\n",
      "Epoch 399/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9887 - model_2_loss: 0.0037 - model_1_loss: 0.0671 - val_loss: 0.9220 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0056\n",
      "Epoch 400/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9840 - model_2_loss: 0.0037 - model_1_loss: 0.0665 - val_loss: 0.9290 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0046\n",
      "Epoch 401/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9853 - model_2_loss: 0.0037 - model_1_loss: 0.0675 - val_loss: 0.9123 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0081\n",
      "Epoch 402/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9850 - model_2_loss: 0.0037 - model_1_loss: 0.0683 - val_loss: 0.9299 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0042\n",
      "Epoch 403/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9847 - model_2_loss: 0.0037 - model_1_loss: 0.0674 - val_loss: 0.9727 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0022\n",
      "Epoch 404/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9798 - model_2_loss: 0.0037 - model_1_loss: 0.0652 - val_loss: 0.9349 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0037\n",
      "Epoch 405/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9802 - model_2_loss: 0.0037 - model_1_loss: 0.0654 - val_loss: 0.9575 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0024\n",
      "Epoch 406/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9836 - model_2_loss: 0.0037 - model_1_loss: 0.0669 - val_loss: 0.9528 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0024\n",
      "Epoch 407/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9837 - model_2_loss: 0.0037 - model_1_loss: 0.0674 - val_loss: 0.9253 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0052\n",
      "Epoch 408/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9848 - model_2_loss: 0.0037 - model_1_loss: 0.0668 - val_loss: 0.9097 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0089\n",
      "Epoch 409/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9822 - model_2_loss: 0.0037 - model_1_loss: 0.0663 - val_loss: 0.9154 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0047\n",
      "Epoch 410/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 0.9807 - model_2_loss: 0.0037 - model_1_loss: 0.0659 - val_loss: 0.9249 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0044\n",
      "Epoch 411/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9848 - model_2_loss: 0.0037 - model_1_loss: 0.0674 - val_loss: 0.9116 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0065\n",
      "Epoch 412/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9835 - model_2_loss: 0.0037 - model_1_loss: 0.0680 - val_loss: 0.9408 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0033\n",
      "Epoch 413/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9776 - model_2_loss: 0.0036 - model_1_loss: 0.0673 - val_loss: 0.9198 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0047\n",
      "Epoch 414/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9813 - model_2_loss: 0.0037 - model_1_loss: 0.0663 - val_loss: 0.9508 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0026\n",
      "Epoch 415/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9786 - model_2_loss: 0.0037 - model_1_loss: 0.0660 - val_loss: 0.9246 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0048\n",
      "Epoch 416/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9800 - model_2_loss: 0.0037 - model_1_loss: 0.0660 - val_loss: 0.8923 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0107\n",
      "Epoch 417/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9802 - model_2_loss: 0.0037 - model_1_loss: 0.0659 - val_loss: 0.9066 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0062\n",
      "Epoch 418/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9819 - model_2_loss: 0.0036 - model_1_loss: 0.0697 - val_loss: 0.9333 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0038\n",
      "Epoch 419/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9782 - model_2_loss: 0.0036 - model_1_loss: 0.0680 - val_loss: 0.9455 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0025\n",
      "Epoch 420/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9755 - model_2_loss: 0.0036 - model_1_loss: 0.0632 - val_loss: 0.9088 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0074\n",
      "Epoch 421/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9833 - model_2_loss: 0.0037 - model_1_loss: 0.0674 - val_loss: 0.8959 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0093\n",
      "Epoch 422/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9817 - model_2_loss: 0.0037 - model_1_loss: 0.0671 - val_loss: 0.9118 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0062\n",
      "Epoch 423/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9763 - model_2_loss: 0.0036 - model_1_loss: 0.0653 - val_loss: 0.8847 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0161\n",
      "Epoch 424/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9763 - model_2_loss: 0.0036 - model_1_loss: 0.0667 - val_loss: 0.9451 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0027\n",
      "Epoch 425/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9789 - model_2_loss: 0.0036 - model_1_loss: 0.0673 - val_loss: 0.9060 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0063\n",
      "Epoch 426/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9786 - model_2_loss: 0.0036 - model_1_loss: 0.0685 - val_loss: 0.9748 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0014\n",
      "Epoch 427/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9788 - model_2_loss: 0.0037 - model_1_loss: 0.0651 - val_loss: 0.9242 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0043\n",
      "Epoch 428/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9749 - model_2_loss: 0.0036 - model_1_loss: 0.0673 - val_loss: 0.9497 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0023\n",
      "Epoch 429/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9727 - model_2_loss: 0.0036 - model_1_loss: 0.0643 - val_loss: 0.8985 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0075\n",
      "Epoch 430/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9761 - model_2_loss: 0.0036 - model_1_loss: 0.0674 - val_loss: 0.9366 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0039\n",
      "Epoch 431/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9765 - model_2_loss: 0.0036 - model_1_loss: 0.0682 - val_loss: 0.9050 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0065\n",
      "Epoch 432/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9728 - model_2_loss: 0.0036 - model_1_loss: 0.0645 - val_loss: 0.9174 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0057\n",
      "Epoch 433/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9770 - model_2_loss: 0.0036 - model_1_loss: 0.0664 - val_loss: 0.9052 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0066\n",
      "Epoch 434/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9747 - model_2_loss: 0.0036 - model_1_loss: 0.0676 - val_loss: 0.9002 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0077\n",
      "Epoch 435/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9787 - model_2_loss: 0.0036 - model_1_loss: 0.0675 - val_loss: 0.9221 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0043\n",
      "Epoch 436/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9710 - model_2_loss: 0.0036 - model_1_loss: 0.0652 - val_loss: 0.9135 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0058\n",
      "Epoch 437/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9734 - model_2_loss: 0.0036 - model_1_loss: 0.0680 - val_loss: 0.9324 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0028\n",
      "Epoch 438/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9715 - model_2_loss: 0.0036 - model_1_loss: 0.0658 - val_loss: 0.9157 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0039\n",
      "Epoch 439/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9721 - model_2_loss: 0.0036 - model_1_loss: 0.0667 - val_loss: 0.9289 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0039\n",
      "Epoch 440/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9700 - model_2_loss: 0.0036 - model_1_loss: 0.0654 - val_loss: 0.9264 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0035\n",
      "Epoch 441/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9689 - model_2_loss: 0.0036 - model_1_loss: 0.0649 - val_loss: 0.9143 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0048\n",
      "Epoch 442/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9719 - model_2_loss: 0.0036 - model_1_loss: 0.0652 - val_loss: 0.9169 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0040\n",
      "Epoch 443/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9727 - model_2_loss: 0.0036 - model_1_loss: 0.0673 - val_loss: 0.9279 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0032\n",
      "Epoch 444/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9732 - model_2_loss: 0.0036 - model_1_loss: 0.0673 - val_loss: 0.9168 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0041\n",
      "Epoch 445/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9774 - model_2_loss: 0.0036 - model_1_loss: 0.0686 - val_loss: 0.9144 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0044\n",
      "Epoch 446/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9716 - model_2_loss: 0.0036 - model_1_loss: 0.0638 - val_loss: 0.9146 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0042\n",
      "Epoch 447/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9649 - model_2_loss: 0.0036 - model_1_loss: 0.0651 - val_loss: 0.9251 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0035\n",
      "Epoch 448/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9732 - model_2_loss: 0.0036 - model_1_loss: 0.0659 - val_loss: 0.9119 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0044\n",
      "Epoch 449/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9718 - model_2_loss: 0.0036 - model_1_loss: 0.0679 - val_loss: 0.8776 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0169\n",
      "Epoch 450/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9709 - model_2_loss: 0.0036 - model_1_loss: 0.0670 - val_loss: 0.9123 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0046\n",
      "Epoch 451/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 0.9747 - model_2_loss: 0.0036 - model_1_loss: 0.0684 - val_loss: 0.9252 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0035\n",
      "Epoch 452/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9694 - model_2_loss: 0.0036 - model_1_loss: 0.0653 - val_loss: 0.9179 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0035\n",
      "Epoch 453/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9673 - model_2_loss: 0.0036 - model_1_loss: 0.0651 - val_loss: 0.9267 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0029\n",
      "Epoch 454/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9685 - model_2_loss: 0.0036 - model_1_loss: 0.0643 - val_loss: 0.9063 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0051\n",
      "Epoch 455/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9657 - model_2_loss: 0.0036 - model_1_loss: 0.0640 - val_loss: 0.8998 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0059\n",
      "Epoch 456/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9696 - model_2_loss: 0.0036 - model_1_loss: 0.0664 - val_loss: 0.9192 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0055\n",
      "Epoch 457/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9630 - model_2_loss: 0.0036 - model_1_loss: 0.0635 - val_loss: 0.8913 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0089\n",
      "Epoch 458/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9639 - model_2_loss: 0.0036 - model_1_loss: 0.0639 - val_loss: 0.8764 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0107\n",
      "Epoch 459/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9679 - model_2_loss: 0.0036 - model_1_loss: 0.0657 - val_loss: 0.9324 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0022\n",
      "Epoch 460/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9675 - model_2_loss: 0.0036 - model_1_loss: 0.0664 - val_loss: 0.9293 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0026\n",
      "Epoch 461/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9645 - model_2_loss: 0.0036 - model_1_loss: 0.0653 - val_loss: 0.8740 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0128\n",
      "Epoch 462/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9631 - model_2_loss: 0.0036 - model_1_loss: 0.0652 - val_loss: 0.9211 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0033\n",
      "Epoch 463/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9653 - model_2_loss: 0.0036 - model_1_loss: 0.0667 - val_loss: 0.9193 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0035\n",
      "Epoch 464/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9661 - model_2_loss: 0.0036 - model_1_loss: 0.0635 - val_loss: 0.9109 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0050\n",
      "Epoch 465/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9678 - model_2_loss: 0.0036 - model_1_loss: 0.0665 - val_loss: 0.9249 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0033\n",
      "Epoch 466/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9644 - model_2_loss: 0.0036 - model_1_loss: 0.0645 - val_loss: 0.9012 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0050\n",
      "Epoch 467/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9666 - model_2_loss: 0.0036 - model_1_loss: 0.0671 - val_loss: 0.9072 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0047\n",
      "Epoch 468/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9648 - model_2_loss: 0.0036 - model_1_loss: 0.0664 - val_loss: 0.9700 - val_model_2_loss: 0.0039 - val_model_1_loss: 0.0014\n",
      "Epoch 469/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9633 - model_2_loss: 0.0036 - model_1_loss: 0.0652 - val_loss: 0.8908 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0063\n",
      "Epoch 470/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9648 - model_2_loss: 0.0036 - model_1_loss: 0.0669 - val_loss: 0.9570 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0015\n",
      "Epoch 471/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9631 - model_2_loss: 0.0036 - model_1_loss: 0.0646 - val_loss: 0.9051 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0043\n",
      "Epoch 472/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9609 - model_2_loss: 0.0036 - model_1_loss: 0.0654 - val_loss: 0.9306 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0027\n",
      "Epoch 473/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9603 - model_2_loss: 0.0036 - model_1_loss: 0.0647 - val_loss: 0.9220 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0038\n",
      "Epoch 474/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9647 - model_2_loss: 0.0036 - model_1_loss: 0.0664 - val_loss: 0.9029 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0037\n",
      "Epoch 475/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9591 - model_2_loss: 0.0036 - model_1_loss: 0.0641 - val_loss: 0.9059 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0052\n",
      "Epoch 476/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9621 - model_2_loss: 0.0036 - model_1_loss: 0.0656 - val_loss: 0.8839 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0120\n",
      "Epoch 477/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9631 - model_2_loss: 0.0036 - model_1_loss: 0.0657 - val_loss: 0.9095 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0043\n",
      "Epoch 478/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9579 - model_2_loss: 0.0036 - model_1_loss: 0.0644 - val_loss: 0.9109 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0039\n",
      "Epoch 479/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9609 - model_2_loss: 0.0036 - model_1_loss: 0.0646 - val_loss: 0.8951 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0053\n",
      "Epoch 480/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9644 - model_2_loss: 0.0036 - model_1_loss: 0.0674 - val_loss: 0.9316 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0023\n",
      "Epoch 481/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9603 - model_2_loss: 0.0036 - model_1_loss: 0.0648 - val_loss: 0.9391 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0024\n",
      "Epoch 482/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9614 - model_2_loss: 0.0036 - model_1_loss: 0.0666 - val_loss: 0.8967 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0054\n",
      "Epoch 483/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9574 - model_2_loss: 0.0036 - model_1_loss: 0.0625 - val_loss: 0.9013 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0045\n",
      "Epoch 484/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9617 - model_2_loss: 0.0036 - model_1_loss: 0.0667 - val_loss: 0.9275 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0028\n",
      "Epoch 485/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9567 - model_2_loss: 0.0036 - model_1_loss: 0.0649 - val_loss: 0.9071 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0040\n",
      "Epoch 486/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9573 - model_2_loss: 0.0036 - model_1_loss: 0.0643 - val_loss: 0.9342 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0023\n",
      "Epoch 487/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9612 - model_2_loss: 0.0036 - model_1_loss: 0.0662 - val_loss: 0.9197 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0024\n",
      "Epoch 488/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9601 - model_2_loss: 0.0036 - model_1_loss: 0.0669 - val_loss: 0.9128 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0029\n",
      "Epoch 489/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9579 - model_2_loss: 0.0036 - model_1_loss: 0.0645 - val_loss: 0.9323 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0020\n",
      "Epoch 490/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9607 - model_2_loss: 0.0036 - model_1_loss: 0.0671 - val_loss: 0.9166 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0029\n",
      "Epoch 491/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9565 - model_2_loss: 0.0036 - model_1_loss: 0.0638 - val_loss: 0.9030 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0054\n",
      "Epoch 492/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 0.9558 - model_2_loss: 0.0036 - model_1_loss: 0.0634 - val_loss: 0.8953 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0047\n",
      "Epoch 493/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9564 - model_2_loss: 0.0036 - model_1_loss: 0.0648 - val_loss: 0.9210 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0028\n",
      "Epoch 494/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9583 - model_2_loss: 0.0036 - model_1_loss: 0.0641 - val_loss: 0.9013 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0037\n",
      "Epoch 495/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9590 - model_2_loss: 0.0036 - model_1_loss: 0.0659 - val_loss: 0.8906 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0058\n",
      "Epoch 496/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9570 - model_2_loss: 0.0036 - model_1_loss: 0.0658 - val_loss: 0.9311 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0018\n",
      "Epoch 497/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9560 - model_2_loss: 0.0036 - model_1_loss: 0.0653 - val_loss: 0.9000 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0040\n",
      "Epoch 498/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9568 - model_2_loss: 0.0036 - model_1_loss: 0.0649 - val_loss: 0.9170 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0026\n",
      "Epoch 499/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9585 - model_2_loss: 0.0036 - model_1_loss: 0.0645 - val_loss: 0.9156 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0034\n",
      "Epoch 500/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9589 - model_2_loss: 0.0036 - model_1_loss: 0.0669 - val_loss: 0.9092 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0035\n",
      "Epoch 501/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9538 - model_2_loss: 0.0036 - model_1_loss: 0.0641 - val_loss: 0.9139 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0030\n",
      "Epoch 502/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9589 - model_2_loss: 0.0036 - model_1_loss: 0.0666 - val_loss: 0.9084 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0029\n",
      "Epoch 503/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9555 - model_2_loss: 0.0036 - model_1_loss: 0.0639 - val_loss: 0.9046 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0036\n",
      "Epoch 504/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9559 - model_2_loss: 0.0036 - model_1_loss: 0.0639 - val_loss: 0.9214 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0022\n",
      "Epoch 505/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9563 - model_2_loss: 0.0036 - model_1_loss: 0.0673 - val_loss: 0.9112 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0027\n",
      "Epoch 506/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9550 - model_2_loss: 0.0036 - model_1_loss: 0.0659 - val_loss: 0.8889 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0049\n",
      "Epoch 507/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9564 - model_2_loss: 0.0036 - model_1_loss: 0.0642 - val_loss: 0.8972 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0047\n",
      "Epoch 508/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9528 - model_2_loss: 0.0036 - model_1_loss: 0.0650 - val_loss: 0.8643 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0106\n",
      "Epoch 509/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9522 - model_2_loss: 0.0036 - model_1_loss: 0.0641 - val_loss: 0.8970 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0043\n",
      "Epoch 510/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9524 - model_2_loss: 0.0036 - model_1_loss: 0.0624 - val_loss: 0.8857 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0051\n",
      "Epoch 511/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9536 - model_2_loss: 0.0036 - model_1_loss: 0.0643 - val_loss: 0.8732 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0077\n",
      "Epoch 512/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9535 - model_2_loss: 0.0036 - model_1_loss: 0.0635 - val_loss: 0.8731 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0082\n",
      "Epoch 513/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9530 - model_2_loss: 0.0036 - model_1_loss: 0.0639 - val_loss: 0.9065 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0033\n",
      "Epoch 514/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9527 - model_2_loss: 0.0036 - model_1_loss: 0.0633 - val_loss: 0.9090 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0038\n",
      "Epoch 515/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9515 - model_2_loss: 0.0036 - model_1_loss: 0.0636 - val_loss: 0.9062 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0026\n",
      "Epoch 516/1000\n",
      "50000/50000 [==============================] - 37s - loss: 0.9503 - model_2_loss: 0.0035 - model_1_loss: 0.0643 - val_loss: 0.8986 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0044\n",
      "Epoch 517/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9538 - model_2_loss: 0.0036 - model_1_loss: 0.0648 - val_loss: 0.8791 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0067\n",
      "Epoch 518/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9551 - model_2_loss: 0.0036 - model_1_loss: 0.0655 - val_loss: 0.9104 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0028\n",
      "Epoch 519/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9505 - model_2_loss: 0.0035 - model_1_loss: 0.0656 - val_loss: 0.8848 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0049\n",
      "Epoch 520/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9490 - model_2_loss: 0.0035 - model_1_loss: 0.0632 - val_loss: 0.9221 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0022\n",
      "Epoch 521/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9522 - model_2_loss: 0.0036 - model_1_loss: 0.0643 - val_loss: 0.8709 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0079\n",
      "Epoch 522/1000\n",
      "50000/50000 [==============================] - 37s - loss: 0.9519 - model_2_loss: 0.0036 - model_1_loss: 0.0635 - val_loss: 0.8928 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0051\n",
      "Epoch 523/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9522 - model_2_loss: 0.0035 - model_1_loss: 0.0647 - val_loss: 0.8869 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0050\n",
      "Epoch 524/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9489 - model_2_loss: 0.0035 - model_1_loss: 0.0639 - val_loss: 0.9381 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0020\n",
      "Epoch 525/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9505 - model_2_loss: 0.0035 - model_1_loss: 0.0652 - val_loss: 0.8948 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0043\n",
      "Epoch 526/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9533 - model_2_loss: 0.0036 - model_1_loss: 0.0634 - val_loss: 0.8682 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0117\n",
      "Epoch 527/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9524 - model_2_loss: 0.0035 - model_1_loss: 0.0662 - val_loss: 0.8962 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0034\n",
      "Epoch 528/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9464 - model_2_loss: 0.0035 - model_1_loss: 0.0620 - val_loss: 0.8775 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0083\n",
      "Epoch 529/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9523 - model_2_loss: 0.0035 - model_1_loss: 0.0652 - val_loss: 0.8657 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0133\n",
      "Epoch 530/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9480 - model_2_loss: 0.0035 - model_1_loss: 0.0621 - val_loss: 0.8871 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0056\n",
      "Epoch 531/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9506 - model_2_loss: 0.0035 - model_1_loss: 0.0651 - val_loss: 0.9294 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0017\n",
      "Epoch 532/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9498 - model_2_loss: 0.0035 - model_1_loss: 0.0653 - val_loss: 0.9043 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0035\n",
      "Epoch 533/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 0.9481 - model_2_loss: 0.0035 - model_1_loss: 0.0632 - val_loss: 0.8727 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0077\n",
      "Epoch 534/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9474 - model_2_loss: 0.0035 - model_1_loss: 0.0638 - val_loss: 0.8804 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0067\n",
      "Epoch 535/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9453 - model_2_loss: 0.0035 - model_1_loss: 0.0624 - val_loss: 0.9139 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0024\n",
      "Epoch 536/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9462 - model_2_loss: 0.0035 - model_1_loss: 0.0637 - val_loss: 0.9180 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0022\n",
      "Epoch 537/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9490 - model_2_loss: 0.0035 - model_1_loss: 0.0649 - val_loss: 0.8885 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0046\n",
      "Epoch 538/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9476 - model_2_loss: 0.0035 - model_1_loss: 0.0635 - val_loss: 0.8953 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0052\n",
      "Epoch 539/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9484 - model_2_loss: 0.0035 - model_1_loss: 0.0643 - val_loss: 0.8729 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0068\n",
      "Epoch 540/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9500 - model_2_loss: 0.0035 - model_1_loss: 0.0665 - val_loss: 0.9322 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0015\n",
      "Epoch 541/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9475 - model_2_loss: 0.0035 - model_1_loss: 0.0636 - val_loss: 0.8928 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0042\n",
      "Epoch 542/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9481 - model_2_loss: 0.0035 - model_1_loss: 0.0642 - val_loss: 0.8726 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0063\n",
      "Epoch 543/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9439 - model_2_loss: 0.0035 - model_1_loss: 0.0641 - val_loss: 0.8846 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0051\n",
      "Epoch 544/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9466 - model_2_loss: 0.0035 - model_1_loss: 0.0645 - val_loss: 0.9172 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0019\n",
      "Epoch 545/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9469 - model_2_loss: 0.0035 - model_1_loss: 0.0633 - val_loss: 0.9007 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0025\n",
      "Epoch 546/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9435 - model_2_loss: 0.0035 - model_1_loss: 0.0622 - val_loss: 0.8643 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0085\n",
      "Epoch 547/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9443 - model_2_loss: 0.0035 - model_1_loss: 0.0646 - val_loss: 0.9054 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0025\n",
      "Epoch 548/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9428 - model_2_loss: 0.0035 - model_1_loss: 0.0635 - val_loss: 0.8910 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0032\n",
      "Epoch 549/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9478 - model_2_loss: 0.0035 - model_1_loss: 0.0655 - val_loss: 0.8834 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0060\n",
      "Epoch 550/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9471 - model_2_loss: 0.0035 - model_1_loss: 0.0647 - val_loss: 0.9408 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0013\n",
      "Epoch 551/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9499 - model_2_loss: 0.0035 - model_1_loss: 0.0651 - val_loss: 0.9351 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0012\n",
      "Epoch 552/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9430 - model_2_loss: 0.0035 - model_1_loss: 0.0647 - val_loss: 0.9032 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0028\n",
      "Epoch 553/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9439 - model_2_loss: 0.0035 - model_1_loss: 0.0656 - val_loss: 0.9445 - val_model_2_loss: 0.0038 - val_model_1_loss: 9.6776e-04\n",
      "Epoch 554/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9489 - model_2_loss: 0.0035 - model_1_loss: 0.0646 - val_loss: 0.9136 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0022\n",
      "Epoch 555/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9389 - model_2_loss: 0.0035 - model_1_loss: 0.0629 - val_loss: 0.8926 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0034\n",
      "Epoch 556/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9448 - model_2_loss: 0.0035 - model_1_loss: 0.0637 - val_loss: 0.8938 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0033\n",
      "Epoch 557/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9428 - model_2_loss: 0.0035 - model_1_loss: 0.0644 - val_loss: 0.8749 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0066\n",
      "Epoch 558/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9428 - model_2_loss: 0.0035 - model_1_loss: 0.0641 - val_loss: 0.8981 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0033\n",
      "Epoch 559/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9430 - model_2_loss: 0.0035 - model_1_loss: 0.0651 - val_loss: 0.8611 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0087\n",
      "Epoch 560/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9408 - model_2_loss: 0.0035 - model_1_loss: 0.0631 - val_loss: 0.9059 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0023\n",
      "Epoch 561/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9423 - model_2_loss: 0.0035 - model_1_loss: 0.0628 - val_loss: 0.9047 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0022\n",
      "Epoch 562/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9425 - model_2_loss: 0.0035 - model_1_loss: 0.0632 - val_loss: 0.9217 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0017\n",
      "Epoch 563/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9408 - model_2_loss: 0.0035 - model_1_loss: 0.0638 - val_loss: 0.8860 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0044\n",
      "Epoch 564/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9413 - model_2_loss: 0.0035 - model_1_loss: 0.0635 - val_loss: 0.8950 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0031\n",
      "Epoch 565/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9381 - model_2_loss: 0.0035 - model_1_loss: 0.0615 - val_loss: 0.8770 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0050\n",
      "Epoch 566/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9403 - model_2_loss: 0.0035 - model_1_loss: 0.0637 - val_loss: 0.9123 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0020\n",
      "Epoch 567/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9364 - model_2_loss: 0.0035 - model_1_loss: 0.0619 - val_loss: 0.8740 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0051\n",
      "Epoch 568/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9413 - model_2_loss: 0.0035 - model_1_loss: 0.0636 - val_loss: 0.8675 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0066\n",
      "Epoch 569/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9409 - model_2_loss: 0.0035 - model_1_loss: 0.0640 - val_loss: 0.8893 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0033\n",
      "Epoch 570/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9372 - model_2_loss: 0.0035 - model_1_loss: 0.0634 - val_loss: 0.9137 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0018\n",
      "Epoch 571/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9388 - model_2_loss: 0.0035 - model_1_loss: 0.0635 - val_loss: 0.8803 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0041\n",
      "Epoch 572/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9385 - model_2_loss: 0.0035 - model_1_loss: 0.0625 - val_loss: 0.8964 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0030\n",
      "Epoch 573/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9412 - model_2_loss: 0.0035 - model_1_loss: 0.0631 - val_loss: 0.8769 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0057\n",
      "Epoch 574/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 0.9394 - model_2_loss: 0.0035 - model_1_loss: 0.0640 - val_loss: 0.9006 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0035\n",
      "Epoch 575/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9396 - model_2_loss: 0.0035 - model_1_loss: 0.0639 - val_loss: 0.8777 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0043\n",
      "Epoch 576/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9416 - model_2_loss: 0.0035 - model_1_loss: 0.0638 - val_loss: 0.9072 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0021\n",
      "Epoch 577/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9358 - model_2_loss: 0.0035 - model_1_loss: 0.0620 - val_loss: 0.8683 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0060\n",
      "Epoch 578/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9363 - model_2_loss: 0.0035 - model_1_loss: 0.0624 - val_loss: 0.8858 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0035\n",
      "Epoch 579/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9379 - model_2_loss: 0.0035 - model_1_loss: 0.0631 - val_loss: 0.8902 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0036\n",
      "Epoch 580/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9379 - model_2_loss: 0.0035 - model_1_loss: 0.0632 - val_loss: 0.8818 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0041\n",
      "Epoch 581/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9426 - model_2_loss: 0.0035 - model_1_loss: 0.0665 - val_loss: 0.8690 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0068\n",
      "Epoch 582/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9334 - model_2_loss: 0.0035 - model_1_loss: 0.0618 - val_loss: 0.8782 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0050\n",
      "Epoch 583/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9375 - model_2_loss: 0.0035 - model_1_loss: 0.0636 - val_loss: 0.8858 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0044\n",
      "Epoch 584/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9364 - model_2_loss: 0.0035 - model_1_loss: 0.0628 - val_loss: 0.8911 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0038\n",
      "Epoch 585/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9400 - model_2_loss: 0.0035 - model_1_loss: 0.0641 - val_loss: 0.8646 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0089\n",
      "Epoch 586/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9388 - model_2_loss: 0.0035 - model_1_loss: 0.0641 - val_loss: 0.8931 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0026\n",
      "Epoch 587/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9391 - model_2_loss: 0.0035 - model_1_loss: 0.0639 - val_loss: 0.8874 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0031\n",
      "Epoch 588/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9332 - model_2_loss: 0.0035 - model_1_loss: 0.0629 - val_loss: 0.9474 - val_model_2_loss: 0.0038 - val_model_1_loss: 0.0013\n",
      "Epoch 589/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9383 - model_2_loss: 0.0035 - model_1_loss: 0.0629 - val_loss: 0.8847 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0033\n",
      "Epoch 590/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9370 - model_2_loss: 0.0035 - model_1_loss: 0.0616 - val_loss: 0.8721 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0047\n",
      "Epoch 591/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9329 - model_2_loss: 0.0035 - model_1_loss: 0.0624 - val_loss: 0.9033 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0022\n",
      "Epoch 592/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9348 - model_2_loss: 0.0035 - model_1_loss: 0.0624 - val_loss: 0.8647 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0053\n",
      "Epoch 593/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9369 - model_2_loss: 0.0035 - model_1_loss: 0.0639 - val_loss: 0.8839 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0037\n",
      "Epoch 594/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9346 - model_2_loss: 0.0035 - model_1_loss: 0.0641 - val_loss: 0.9074 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0028\n",
      "Epoch 595/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9334 - model_2_loss: 0.0035 - model_1_loss: 0.0634 - val_loss: 0.9040 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0023\n",
      "Epoch 596/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9362 - model_2_loss: 0.0035 - model_1_loss: 0.0632 - val_loss: 0.8643 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0054\n",
      "Epoch 597/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9340 - model_2_loss: 0.0035 - model_1_loss: 0.0639 - val_loss: 0.8780 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0039\n",
      "Epoch 598/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9408 - model_2_loss: 0.0035 - model_1_loss: 0.0647 - val_loss: 0.8812 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0034\n",
      "Epoch 599/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9377 - model_2_loss: 0.0035 - model_1_loss: 0.0632 - val_loss: 0.9022 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0024\n",
      "Epoch 600/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9359 - model_2_loss: 0.0035 - model_1_loss: 0.0626 - val_loss: 0.9141 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0017\n",
      "Epoch 601/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9345 - model_2_loss: 0.0035 - model_1_loss: 0.0629 - val_loss: 0.8916 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0029\n",
      "Epoch 602/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9382 - model_2_loss: 0.0035 - model_1_loss: 0.0650 - val_loss: 0.8854 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0026\n",
      "Epoch 603/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9357 - model_2_loss: 0.0035 - model_1_loss: 0.0642 - val_loss: 0.8997 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0021\n",
      "Epoch 604/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9351 - model_2_loss: 0.0035 - model_1_loss: 0.0633 - val_loss: 0.9263 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0011\n",
      "Epoch 605/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9357 - model_2_loss: 0.0035 - model_1_loss: 0.0638 - val_loss: 0.8713 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0041\n",
      "Epoch 606/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9300 - model_2_loss: 0.0035 - model_1_loss: 0.0611 - val_loss: 0.8596 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0065\n",
      "Epoch 607/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9360 - model_2_loss: 0.0035 - model_1_loss: 0.0645 - val_loss: 0.8954 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0023\n",
      "Epoch 608/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9307 - model_2_loss: 0.0035 - model_1_loss: 0.0632 - val_loss: 0.9327 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0010\n",
      "Epoch 609/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9306 - model_2_loss: 0.0035 - model_1_loss: 0.0624 - val_loss: 0.9008 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0022\n",
      "Epoch 610/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9314 - model_2_loss: 0.0035 - model_1_loss: 0.0616 - val_loss: 0.8789 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0037\n",
      "Epoch 611/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9337 - model_2_loss: 0.0035 - model_1_loss: 0.0629 - val_loss: 0.8592 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0071\n",
      "Epoch 612/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9316 - model_2_loss: 0.0035 - model_1_loss: 0.0640 - val_loss: 0.8864 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0030\n",
      "Epoch 613/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9338 - model_2_loss: 0.0035 - model_1_loss: 0.0636 - val_loss: 0.8975 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0019\n",
      "Epoch 614/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9309 - model_2_loss: 0.0035 - model_1_loss: 0.0611 - val_loss: 0.8927 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0025\n",
      "Epoch 615/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 0.9277 - model_2_loss: 0.0035 - model_1_loss: 0.0615 - val_loss: 0.9188 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0014\n",
      "Epoch 616/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9315 - model_2_loss: 0.0035 - model_1_loss: 0.0629 - val_loss: 0.9197 - val_model_2_loss: 0.0037 - val_model_1_loss: 0.0014\n",
      "Epoch 617/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9328 - model_2_loss: 0.0035 - model_1_loss: 0.0630 - val_loss: 0.9050 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0016\n",
      "Epoch 618/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9245 - model_2_loss: 0.0035 - model_1_loss: 0.0597 - val_loss: 0.8757 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0040\n",
      "Epoch 619/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9300 - model_2_loss: 0.0035 - model_1_loss: 0.0611 - val_loss: 0.8932 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0021\n",
      "Epoch 620/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9306 - model_2_loss: 0.0035 - model_1_loss: 0.0638 - val_loss: 0.8615 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0054\n",
      "Epoch 621/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9312 - model_2_loss: 0.0035 - model_1_loss: 0.0646 - val_loss: 0.8766 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0033\n",
      "Epoch 622/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9318 - model_2_loss: 0.0035 - model_1_loss: 0.0641 - val_loss: 0.8620 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0051\n",
      "Epoch 623/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9297 - model_2_loss: 0.0035 - model_1_loss: 0.0635 - val_loss: 0.8965 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0020\n",
      "Epoch 624/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9279 - model_2_loss: 0.0035 - model_1_loss: 0.0618 - val_loss: 0.8685 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0037\n",
      "Epoch 625/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9278 - model_2_loss: 0.0035 - model_1_loss: 0.0632 - val_loss: 0.8879 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0027\n",
      "Epoch 626/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9303 - model_2_loss: 0.0035 - model_1_loss: 0.0640 - val_loss: 0.8997 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0023\n",
      "Epoch 627/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9300 - model_2_loss: 0.0035 - model_1_loss: 0.0632 - val_loss: 0.8637 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0045\n",
      "Epoch 628/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9268 - model_2_loss: 0.0035 - model_1_loss: 0.0617 - val_loss: 0.8839 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0032\n",
      "Epoch 629/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9286 - model_2_loss: 0.0035 - model_1_loss: 0.0629 - val_loss: 0.9072 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0014\n",
      "Epoch 630/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9262 - model_2_loss: 0.0035 - model_1_loss: 0.0618 - val_loss: 0.8694 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0039\n",
      "Epoch 631/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9278 - model_2_loss: 0.0035 - model_1_loss: 0.0611 - val_loss: 0.9116 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0019\n",
      "Epoch 632/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9293 - model_2_loss: 0.0035 - model_1_loss: 0.0615 - val_loss: 0.8831 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0025\n",
      "Epoch 633/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9288 - model_2_loss: 0.0035 - model_1_loss: 0.0630 - val_loss: 0.8867 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0029\n",
      "Epoch 634/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9269 - model_2_loss: 0.0035 - model_1_loss: 0.0628 - val_loss: 0.8576 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0054\n",
      "Epoch 635/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9270 - model_2_loss: 0.0035 - model_1_loss: 0.0623 - val_loss: 0.8997 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0018\n",
      "Epoch 636/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9274 - model_2_loss: 0.0035 - model_1_loss: 0.0625 - val_loss: 0.8289 - val_model_2_loss: 0.0032 - val_model_1_loss: 0.0184\n",
      "Epoch 637/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9244 - model_2_loss: 0.0035 - model_1_loss: 0.0616 - val_loss: 0.8768 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0033\n",
      "Epoch 638/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9311 - model_2_loss: 0.0035 - model_1_loss: 0.0639 - val_loss: 0.8802 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0032\n",
      "Epoch 639/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9285 - model_2_loss: 0.0035 - model_1_loss: 0.0623 - val_loss: 0.9037 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0020\n",
      "Epoch 640/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9277 - model_2_loss: 0.0035 - model_1_loss: 0.0646 - val_loss: 0.8749 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0033\n",
      "Epoch 641/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9229 - model_2_loss: 0.0034 - model_1_loss: 0.0609 - val_loss: 0.8337 - val_model_2_loss: 0.0033 - val_model_1_loss: 0.0175\n",
      "Epoch 642/1000\n",
      "50000/50000 [==============================] - 37s - loss: 0.9257 - model_2_loss: 0.0035 - model_1_loss: 0.0624 - val_loss: 0.8714 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0038\n",
      "Epoch 643/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9267 - model_2_loss: 0.0035 - model_1_loss: 0.0626 - val_loss: 0.9072 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0017\n",
      "Epoch 644/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9256 - model_2_loss: 0.0035 - model_1_loss: 0.0625 - val_loss: 0.8652 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0044\n",
      "Epoch 645/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9259 - model_2_loss: 0.0035 - model_1_loss: 0.0605 - val_loss: 0.8794 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0035\n",
      "Epoch 646/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9270 - model_2_loss: 0.0034 - model_1_loss: 0.0647 - val_loss: 0.8740 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0032\n",
      "Epoch 647/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9216 - model_2_loss: 0.0034 - model_1_loss: 0.0611 - val_loss: 0.8532 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0065\n",
      "Epoch 648/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9247 - model_2_loss: 0.0035 - model_1_loss: 0.0616 - val_loss: 0.8598 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0042\n",
      "Epoch 649/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9224 - model_2_loss: 0.0034 - model_1_loss: 0.0620 - val_loss: 0.8797 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0029\n",
      "Epoch 650/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9268 - model_2_loss: 0.0035 - model_1_loss: 0.0631 - val_loss: 0.8528 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0055\n",
      "Epoch 651/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9240 - model_2_loss: 0.0034 - model_1_loss: 0.0620 - val_loss: 0.8521 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0056\n",
      "Epoch 652/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9191 - model_2_loss: 0.0034 - model_1_loss: 0.0598 - val_loss: 0.8558 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0046\n",
      "Epoch 653/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9264 - model_2_loss: 0.0035 - model_1_loss: 0.0638 - val_loss: 0.8816 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0023\n",
      "Epoch 654/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9259 - model_2_loss: 0.0034 - model_1_loss: 0.0644 - val_loss: 0.8546 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0075\n",
      "Epoch 655/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9280 - model_2_loss: 0.0035 - model_1_loss: 0.0628 - val_loss: 0.8886 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0022\n",
      "Epoch 656/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 38s - loss: 0.9225 - model_2_loss: 0.0034 - model_1_loss: 0.0615 - val_loss: 0.8400 - val_model_2_loss: 0.0033 - val_model_1_loss: 0.0096\n",
      "Epoch 657/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9240 - model_2_loss: 0.0035 - model_1_loss: 0.0615 - val_loss: 0.8452 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0076\n",
      "Epoch 658/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9250 - model_2_loss: 0.0034 - model_1_loss: 0.0636 - val_loss: 0.9174 - val_model_2_loss: 0.0037 - val_model_1_loss: 7.4275e-04\n",
      "Epoch 659/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9260 - model_2_loss: 0.0035 - model_1_loss: 0.0624 - val_loss: 0.8615 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0043\n",
      "Epoch 660/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9248 - model_2_loss: 0.0034 - model_1_loss: 0.0642 - val_loss: 0.8868 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0025\n",
      "Epoch 661/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9183 - model_2_loss: 0.0034 - model_1_loss: 0.0609 - val_loss: 0.8779 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0025\n",
      "Epoch 662/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9200 - model_2_loss: 0.0034 - model_1_loss: 0.0594 - val_loss: 0.8884 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0027\n",
      "Epoch 663/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9249 - model_2_loss: 0.0034 - model_1_loss: 0.0647 - val_loss: 0.8947 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0021\n",
      "Epoch 664/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9166 - model_2_loss: 0.0034 - model_1_loss: 0.0604 - val_loss: 0.8563 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0056\n",
      "Epoch 665/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9206 - model_2_loss: 0.0034 - model_1_loss: 0.0611 - val_loss: 0.8576 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0052\n",
      "Epoch 666/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9249 - model_2_loss: 0.0035 - model_1_loss: 0.0612 - val_loss: 0.8770 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0033\n",
      "Epoch 667/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9246 - model_2_loss: 0.0034 - model_1_loss: 0.0623 - val_loss: 0.9021 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0018\n",
      "Epoch 668/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9188 - model_2_loss: 0.0034 - model_1_loss: 0.0617 - val_loss: 0.8508 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0058\n",
      "Epoch 669/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9224 - model_2_loss: 0.0034 - model_1_loss: 0.0629 - val_loss: 0.8598 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0059\n",
      "Epoch 670/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9194 - model_2_loss: 0.0034 - model_1_loss: 0.0618 - val_loss: 0.8877 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0020\n",
      "Epoch 671/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9229 - model_2_loss: 0.0034 - model_1_loss: 0.0613 - val_loss: 0.8595 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0040\n",
      "Epoch 672/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9216 - model_2_loss: 0.0034 - model_1_loss: 0.0615 - val_loss: 0.8874 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0023\n",
      "Epoch 673/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9173 - model_2_loss: 0.0034 - model_1_loss: 0.0605 - val_loss: 0.8607 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0039\n",
      "Epoch 674/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9205 - model_2_loss: 0.0034 - model_1_loss: 0.0612 - val_loss: 0.8569 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0039\n",
      "Epoch 675/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9197 - model_2_loss: 0.0034 - model_1_loss: 0.0626 - val_loss: 0.8573 - val_model_2_loss: 0.0034 - val_model_1_loss: 0.0044\n",
      "Epoch 676/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9213 - model_2_loss: 0.0034 - model_1_loss: 0.0618 - val_loss: 0.8979 - val_model_2_loss: 0.0036 - val_model_1_loss: 0.0017\n",
      "Epoch 677/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9230 - model_2_loss: 0.0034 - model_1_loss: 0.0637 - val_loss: 0.8336 - val_model_2_loss: 0.0033 - val_model_1_loss: 0.0095\n",
      "Epoch 678/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9183 - model_2_loss: 0.0034 - model_1_loss: 0.0624 - val_loss: 0.8759 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0031\n",
      "Epoch 679/1000\n",
      "50000/50000 [==============================] - 38s - loss: 0.9167 - model_2_loss: 0.0034 - model_1_loss: 0.0613 - val_loss: 0.8685 - val_model_2_loss: 0.0035 - val_model_1_loss: 0.0034\n",
      "Epoch 680/1000\n",
      "31232/50000 [=================>............] - ETA: 13s - loss: 0.9210 - model_2_loss: 0.0034 - model_1_loss: 0.0630"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-139049dd75cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;31m#callbacks = [model0_loss]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m        )\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model0.optimizer = Adam(0.00001)\n",
    "model0.loss_weights = {'model_2': 250.0, 'model_1': 1.0} #model_2 = perception, model_1 = classifier\n",
    "model0.fit(x_train, {'model_2': percept_train, 'model_1':y0_train}, \n",
    "        validation_data = (x_validate, {'model_2': percept_validate,'model_1': y0_validate}),\n",
    "        epochs = 1000,\n",
    "        batch_size = 512,\n",
    "        shuffle = True,\n",
    "        #callbacks = [model0_loss]\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator = Model(inp0, out0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_fake = generator.predict(x_test)\n",
    "x_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAZ0CAYAAACA0owTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkuEJAJU+AD+8oihv9T2pAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22f90c7080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''Lets see some of the generated images'''\n",
    "num = 10\n",
    "fig,axis = plt.subplots(nrows = num, ncols=2, figsize=(10,30))\n",
    "for i in range(num):\n",
    "    axis[i,0].imshow(x_test[i,:,:,0], cmap='gray')\n",
    "    axis[i,0].get_xaxis().set_visible(False)\n",
    "    axis[i,0].get_yaxis().set_visible(False)\n",
    "    axis[i,1].imshow(x_fake[i,:,:,0], cmap='gray')\n",
    "    axis[i,1].get_xaxis().set_visible(False)\n",
    "    axis[i,1].get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy on test set: 99.39%\n"
     ]
    }
   ],
   "source": [
    "classifier_accuracy_test = classifier.evaluate(x_test, y_test, verbose=0)\n",
    "print('Classifier accuracy on test set: %.2f%%' % (classifier_accuracy_test[1] * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier accuracy on fake test set: 9.84%\n"
     ]
    }
   ],
   "source": [
    "classifier_accuracy_fake = classifier.evaluate(x_fake, y_test, verbose=0)\n",
    "print('Classifier accuracy on fake test set: %.2f%%' % (classifier_accuracy_fake[1] * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see how the classifier is fooled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAaFCAYAAADZLa+pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22f8ae3f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake_predictions = classifier.predict(x_fake)\n",
    "fig,axis = plt.subplots(nrows = num, ncols=2, figsize=(10,30))\n",
    "for i in range(num):\n",
    "    axis[i,0].imshow(x_test[i,:,:,0], cmap='gray')\n",
    "    axis[i,0].get_xaxis().set_visible(False)\n",
    "    axis[i,0].get_yaxis().set_visible(False)\n",
    "    axis[i,1].imshow(x_fake[i,:,:,0], cmap='gray')\n",
    "    axis[i,1].get_xaxis().set_visible(False)\n",
    "    axis[i,1].get_yaxis().set_visible(False)\n",
    "    title = 'Prediction: ' + str(np.argmax(fake_predictions[i]))\\\n",
    "            + ' (' +\\\n",
    "            '%.2f%%' % (np.amax(fake_predictions[i])*100.0)\\\n",
    "            + ')'\n",
    "    axis[i,1].set_title(title, fontsize = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator.save('generator_model.h5')\n",
    "classifier.save('mnist_classifier_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
